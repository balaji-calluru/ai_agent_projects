{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Building an AI Agent using OpenAI API\n",
        "\n",
        "## Overview\n",
        "\n",
        "This comprehensive guide will teach you how to build intelligent AI agents using the OpenAI API. You'll learn to create agents that can understand data context, process natural language queries, and provide intelligent responses using GPT models.\n",
        "\n",
        "### What You'll Learn\n",
        "\n",
        "- How to set up and configure the OpenAI API\n",
        "- How to build an AI agent that processes structured data\n",
        "- How to create interactive query systems\n",
        "- Best practices for prompt engineering\n",
        "- Handling edge cases and errors\n",
        "- Troubleshooting common issues\n",
        "\n",
        "### What is an AI Agent?\n",
        "\n",
        "An AI agent is an autonomous system that can:\n",
        "- **Understand context**: Process and comprehend data structures\n",
        "- **Reason**: Analyze information step-by-step\n",
        "- **Respond**: Generate natural language answers to user queries\n",
        "- **Interact**: Engage in conversational exchanges\n",
        "\n",
        "### Use Cases\n",
        "\n",
        "- Data analysis assistants\n",
        "- Customer support chatbots\n",
        "- Business intelligence tools\n",
        "- Educational tutoring systems\n",
        "- Research assistants\n",
        "\n",
        "---\n",
        "\n",
        "## Table of Contents\n",
        "\n",
        "1. [Prerequisites](#prerequisites)\n",
        "2. [OpenAI API Setup](#openai-api-setup)\n",
        "3. [Project Setup](#project-setup)\n",
        "4. [Loading and Understanding Data](#loading-and-understanding-data)\n",
        "5. [Building the AI Agent](#building-the-ai-agent)\n",
        "6. [Creating Interactive Interface](#creating-interactive-interface)\n",
        "7. [Testing and Examples](#testing-and-examples)\n",
        "8. [Advanced Features](#advanced-features)\n",
        "9. [Edge Cases and Error Handling](#edge-cases-and-error-handling)\n",
        "10. [Troubleshooting Guide](#troubleshooting-guide)\n",
        "11. [Exercises](#exercises)\n",
        "12. [Summary](#summary)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prerequisites\n",
        "\n",
        "Before we begin, make sure you have:\n",
        "\n",
        "1. **Python 3.8+** installed on your system\n",
        "2. **OpenAI API Account** with access to GPT models\n",
        "3. **Basic knowledge** of Python and pandas\n",
        "4. **Required packages** (we'll install these in the next section)\n",
        "\n",
        "### Required Python Packages\n",
        "\n",
        "- `openai` - OpenAI Python SDK\n",
        "- `pandas` - Data manipulation and analysis\n",
        "- `python-dotenv` - Environment variable management (recommended)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages (uncomment if needed)\n",
        "# !pip install openai pandas python-dotenv\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## OpenAI API Setup\n",
        "\n",
        "### Step 1: Create an OpenAI Account\n",
        "\n",
        "1. Visit [OpenAI's website](https://platform.openai.com/)\n",
        "2. Click \"Sign Up\" or \"Log In\" if you already have an account\n",
        "3. Complete the registration process\n",
        "\n",
        "### Step 2: Get Your API Key\n",
        "\n",
        "1. Once logged in, navigate to the **API Keys** section:\n",
        "   - Click on your profile icon (top right)\n",
        "   - Select \"API Keys\" from the dropdown menu\n",
        "   - Or go directly to: https://platform.openai.com/api-keys\n",
        "\n",
        "2. Create a new API key:\n",
        "   - Click \"Create new secret key\"\n",
        "   - Give it a name (e.g., \"AI Agent Project\")\n",
        "   - **Important**: Copy the key immediately - you won't be able to see it again!\n",
        "\n",
        "3. Save your API key securely:\n",
        "   - Never commit API keys to version control (Git)\n",
        "   - Store it in environment variables or a `.env` file\n",
        "   - Keep it private and don't share it publicly\n",
        "\n",
        "### Step 3: Understanding API Pricing\n",
        "\n",
        "- OpenAI charges based on **tokens** used (input + output)\n",
        "- Different models have different pricing:\n",
        "  - GPT-4o: More expensive but more capable\n",
        "  - GPT-3.5-turbo: More affordable, good for many tasks\n",
        "- Check current pricing at: https://openai.com/pricing\n",
        "- Monitor your usage in the OpenAI dashboard: https://platform.openai.com/usage\n",
        "\n",
        "### Step 4: Setting Up API Key in Your Code\n",
        "\n",
        "**Method 1: Environment Variables (Recommended)**\n",
        "\n",
        "Create a `.env` file in your project directory:\n",
        "```\n",
        "OPENAI_API_KEY=your-api-key-here\n",
        "```\n",
        "\n",
        "**Method 2: Direct Assignment (For Testing Only)**\n",
        "\n",
        "‚ö†Ô∏è **Warning**: Only use this for local testing. Never commit API keys to version control!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ OpenAI client initialized using .env file method\n",
            "Last 5 characters of API Key: OYloA\n"
          ]
        }
      ],
      "source": [
        "# Import required libraries\n",
        "import os\n",
        "import pandas as pd\n",
        "from openai import OpenAI\n",
        "from dotenv import load_dotenv  # Optional: for .env file support\n",
        "\n",
        "# ============================================================================\n",
        "# API KEY LOADING METHOD\n",
        "# ============================================================================\n",
        "# Choose one of the following methods:\n",
        "#   - 'DOTENV': Load from .env file (recommended for development)\n",
        "#   - 'ENV': Load from environment variables (recommended for production)\n",
        "#   - 'DIRECT': Direct assignment (for testing only - NOT for production!)\n",
        "# ============================================================================\n",
        "LOAD_METHOD = 'DOTENV'  # Change this to 'ENV', 'DIRECT', or 'DOTENV'\n",
        "\n",
        "# Initialize OpenAI client based on LOAD_METHOD\n",
        "client = None\n",
        "api_key = None\n",
        "\n",
        "try:\n",
        "    if LOAD_METHOD == 'DOTENV':\n",
        "        # Method 1: Load from .env file\n",
        "        # Create a .env file in your project root with: OPENAI_API_KEY=your-key-here\n",
        "        load_dotenv()\n",
        "        api_key = os.getenv('OPENAI_API_KEY')\n",
        "        if not api_key:\n",
        "            raise ValueError(\"API key not found in .env file. Please create a .env file with OPENAI_API_KEY=your-key\")\n",
        "        client = OpenAI(api_key=api_key)\n",
        "        print(\"‚úÖ OpenAI client initialized using .env file method\")\n",
        "        \n",
        "    elif LOAD_METHOD == 'ENV':\n",
        "        # Method 2: Load from environment variables\n",
        "        # Set it in your terminal: export OPENAI_API_KEY='your-key-here'\n",
        "        api_key = os.getenv('OPENAI_API_KEY')\n",
        "        if not api_key:\n",
        "            raise ValueError(\"API key not found in environment variables. Please set OPENAI_API_KEY\")\n",
        "        client = OpenAI(api_key=api_key)\n",
        "        print(\"‚úÖ OpenAI client initialized using environment variable method\")\n",
        "        \n",
        "    elif LOAD_METHOD == 'DIRECT':\n",
        "        # Method 3: Direct assignment (FOR TESTING ONLY!)\n",
        "        # ‚ö†Ô∏è WARNING: Never commit this to version control!\n",
        "        # Replace 'YOUR_OPENAI_API_KEY_HERE' with your actual API key\n",
        "        api_key = 'YOUR_OPENAI_API_KEY_HERE'\n",
        "        if api_key == 'YOUR_OPENAI_API_KEY_HERE':\n",
        "            raise ValueError(\"Please replace 'YOUR_OPENAI_API_KEY_HERE' with your actual API key\")\n",
        "        client = OpenAI(api_key=api_key)\n",
        "        print(\"‚úÖ OpenAI client initialized using direct assignment method\")\n",
        "        print(\"‚ö†Ô∏è  WARNING: Direct assignment is for testing only. Use ENV or DOTENV for production!\")\n",
        "        \n",
        "    else:\n",
        "        raise ValueError(f\"Invalid LOAD_METHOD: {LOAD_METHOD}. Use 'ENV', 'DIRECT', or 'DOTENV'\")\n",
        "    \n",
        "    print(f\"Last 5 characters of API Key: {api_key[-5:]}\")\n",
        "        \n",
        "except ValueError as e:\n",
        "    print(f\"‚ùå Configuration Error: {e}\")\n",
        "    print(\"\\nüìù Setup Instructions:\")\n",
        "    print(\"  - For DOTENV: Create a .env file with OPENAI_API_KEY=your-key\")\n",
        "    print(\"  - For ENV: Run 'export OPENAI_API_KEY=your-key' in terminal\")\n",
        "    print(\"  - For DIRECT: Replace 'YOUR_OPENAI_API_KEY_HERE' with your actual key\")\n",
        "    raise\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error initializing OpenAI client: {e}\")\n",
        "    print(\"\\nPlease check:\")\n",
        "    print(\"  1. Your API key is valid\")\n",
        "    print(\"  2. You have internet connection\")\n",
        "    print(\"  3. Your OpenAI account has sufficient credits\")\n",
        "    raise\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Project Setup\n",
        "\n",
        "### Understanding the Project Structure\n",
        "\n",
        "We'll build an AI agent that:\n",
        "1. **Loads structured data** (loan prediction dataset)\n",
        "2. **Summarizes the data** to understand its structure\n",
        "3. **Accepts natural language queries** from users\n",
        "4. **Uses GPT models** to analyze and respond intelligently\n",
        "5. **Provides conversational answers** based on the data\n",
        "\n",
        "### Why Summarize Data Instead of Sending All Data?\n",
        "\n",
        "- **Token Limits**: GPT models have token limits (e.g., GPT-4o has 128k tokens)\n",
        "- **Cost Efficiency**: Sending entire datasets is expensive\n",
        "- **Performance**: Smaller prompts process faster\n",
        "- **Focus**: Summaries help the model understand structure without overwhelming detail\n",
        "\n",
        "### Key Concepts\n",
        "\n",
        "**Prompt Engineering**: The art of crafting effective prompts to get desired responses from LLMs.\n",
        "\n",
        "**Context Window**: The maximum amount of text (tokens) a model can process in one request.\n",
        "\n",
        "**Temperature**: Controls randomness in responses (0.0 = deterministic, 1.0 = creative).\n",
        "\n",
        "**Max Tokens**: Limits the length of the model's response.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Loading and Understanding Data\n",
        "\n",
        "### About the Dataset\n",
        "\n",
        "We'll use a loan prediction dataset that contains information about loan applicants. This dataset typically includes:\n",
        "- Applicant demographics\n",
        "- Financial information\n",
        "- Loan details\n",
        "- Approval status\n",
        "\n",
        "### Download the Dataset\n",
        "\n",
        "You can download the dataset from:\n",
        "- Kaggle: Search for \"loan prediction dataset\"\n",
        "  - https://www.kaggle.com/datasets?search=load+prediction+dataset\n",
        "  - https://www.kaggle.com/datasets/deeplumiere/load-pred-dataset\n",
        "- Or use any CSV file with structured data for practice\n",
        "\n",
        "**Note**: If you don't have the dataset, we'll create a sample dataset for demonstration purposes.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Dataset loaded from CSV file successfully!\n",
            "   File path: ../data/Load-Prediction-Data/loan_prediction.csv\n",
            "\n",
            "Dataset shape: (20000, 22)\n",
            "Rows: 20000, Columns: 22\n",
            "\n",
            "First few rows:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>gender</th>\n",
              "      <th>marital_status</th>\n",
              "      <th>education_level</th>\n",
              "      <th>annual_income</th>\n",
              "      <th>monthly_income</th>\n",
              "      <th>employment_status</th>\n",
              "      <th>debt_to_income_ratio</th>\n",
              "      <th>credit_score</th>\n",
              "      <th>loan_amount</th>\n",
              "      <th>...</th>\n",
              "      <th>loan_term</th>\n",
              "      <th>installment</th>\n",
              "      <th>grade_subgrade</th>\n",
              "      <th>num_of_open_accounts</th>\n",
              "      <th>total_credit_limit</th>\n",
              "      <th>current_balance</th>\n",
              "      <th>delinquency_history</th>\n",
              "      <th>public_records</th>\n",
              "      <th>num_of_delinquencies</th>\n",
              "      <th>loan_paid_back</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>59</td>\n",
              "      <td>Male</td>\n",
              "      <td>Married</td>\n",
              "      <td>Master's</td>\n",
              "      <td>24240.19</td>\n",
              "      <td>2020.02</td>\n",
              "      <td>Employed</td>\n",
              "      <td>0.074</td>\n",
              "      <td>743</td>\n",
              "      <td>17173.72</td>\n",
              "      <td>...</td>\n",
              "      <td>36</td>\n",
              "      <td>581.88</td>\n",
              "      <td>B5</td>\n",
              "      <td>7</td>\n",
              "      <td>40833.47</td>\n",
              "      <td>24302.07</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>72</td>\n",
              "      <td>Female</td>\n",
              "      <td>Married</td>\n",
              "      <td>Bachelor's</td>\n",
              "      <td>20172.98</td>\n",
              "      <td>1681.08</td>\n",
              "      <td>Employed</td>\n",
              "      <td>0.219</td>\n",
              "      <td>531</td>\n",
              "      <td>22663.89</td>\n",
              "      <td>...</td>\n",
              "      <td>60</td>\n",
              "      <td>573.17</td>\n",
              "      <td>F1</td>\n",
              "      <td>5</td>\n",
              "      <td>27968.01</td>\n",
              "      <td>10803.01</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>49</td>\n",
              "      <td>Female</td>\n",
              "      <td>Single</td>\n",
              "      <td>High School</td>\n",
              "      <td>26181.80</td>\n",
              "      <td>2181.82</td>\n",
              "      <td>Employed</td>\n",
              "      <td>0.234</td>\n",
              "      <td>779</td>\n",
              "      <td>3631.36</td>\n",
              "      <td>...</td>\n",
              "      <td>60</td>\n",
              "      <td>76.32</td>\n",
              "      <td>B4</td>\n",
              "      <td>2</td>\n",
              "      <td>15502.25</td>\n",
              "      <td>4505.44</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>35</td>\n",
              "      <td>Female</td>\n",
              "      <td>Single</td>\n",
              "      <td>High School</td>\n",
              "      <td>11873.84</td>\n",
              "      <td>989.49</td>\n",
              "      <td>Employed</td>\n",
              "      <td>0.264</td>\n",
              "      <td>809</td>\n",
              "      <td>14939.23</td>\n",
              "      <td>...</td>\n",
              "      <td>36</td>\n",
              "      <td>468.07</td>\n",
              "      <td>A5</td>\n",
              "      <td>7</td>\n",
              "      <td>18157.79</td>\n",
              "      <td>5525.63</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>63</td>\n",
              "      <td>Other</td>\n",
              "      <td>Single</td>\n",
              "      <td>Other</td>\n",
              "      <td>25326.44</td>\n",
              "      <td>2110.54</td>\n",
              "      <td>Employed</td>\n",
              "      <td>0.260</td>\n",
              "      <td>663</td>\n",
              "      <td>16551.71</td>\n",
              "      <td>...</td>\n",
              "      <td>60</td>\n",
              "      <td>395.50</td>\n",
              "      <td>D5</td>\n",
              "      <td>1</td>\n",
              "      <td>17467.56</td>\n",
              "      <td>3593.91</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows √ó 22 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   age  gender marital_status education_level  annual_income  monthly_income  \\\n",
              "0   59    Male        Married        Master's       24240.19         2020.02   \n",
              "1   72  Female        Married      Bachelor's       20172.98         1681.08   \n",
              "2   49  Female         Single     High School       26181.80         2181.82   \n",
              "3   35  Female         Single     High School       11873.84          989.49   \n",
              "4   63   Other         Single           Other       25326.44         2110.54   \n",
              "\n",
              "  employment_status  debt_to_income_ratio  credit_score  loan_amount  ...  \\\n",
              "0          Employed                 0.074           743     17173.72  ...   \n",
              "1          Employed                 0.219           531     22663.89  ...   \n",
              "2          Employed                 0.234           779      3631.36  ...   \n",
              "3          Employed                 0.264           809     14939.23  ...   \n",
              "4          Employed                 0.260           663     16551.71  ...   \n",
              "\n",
              "  loan_term  installment  grade_subgrade  num_of_open_accounts  \\\n",
              "0        36       581.88              B5                     7   \n",
              "1        60       573.17              F1                     5   \n",
              "2        60        76.32              B4                     2   \n",
              "3        36       468.07              A5                     7   \n",
              "4        60       395.50              D5                     1   \n",
              "\n",
              "  total_credit_limit  current_balance  delinquency_history  public_records  \\\n",
              "0           40833.47         24302.07                    1               0   \n",
              "1           27968.01         10803.01                    1               0   \n",
              "2           15502.25          4505.44                    0               0   \n",
              "3           18157.79          5525.63                    4               0   \n",
              "4           17467.56          3593.91                    2               0   \n",
              "\n",
              "   num_of_delinquencies  loan_paid_back  \n",
              "0                     1               1  \n",
              "1                     3               1  \n",
              "2                     0               1  \n",
              "3                     5               1  \n",
              "4                     2               1  \n",
              "\n",
              "[5 rows x 22 columns]"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load the loan prediction dataset from the data folder\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Path to the dataset (notebook is in src/, data is in ../data/)\n",
        "data_path = '../data/Load-Prediction-Data/loan_prediction.csv'\n",
        "\n",
        "# Check if file exists, otherwise create sample data\n",
        "if os.path.exists(data_path):\n",
        "    # Option 1: Load from CSV file\n",
        "    df = pd.read_csv(data_path)\n",
        "    print(\"‚úÖ Dataset loaded from CSV file successfully!\")\n",
        "    print(f\"   File path: {data_path}\")\n",
        "else:\n",
        "    # Option 2: Create a sample dataset for demonstration (if file not found)\n",
        "    print(\"‚ö†Ô∏è  Dataset file not found. Creating sample data for demonstration...\")\n",
        "    print(f\"   Expected path: {data_path}\")\n",
        "    print(\"   If you have the dataset, please ensure it's in the correct location.\")\n",
        "    \n",
        "    np.random.seed(42)\n",
        "    n_samples = 500\n",
        "\n",
        "    data = {\n",
        "        'Loan_ID': [f'LP{i:04d}' for i in range(1, n_samples + 1)],\n",
        "        'Gender': np.random.choice(['Male', 'Female'], n_samples),\n",
        "        'Married': np.random.choice(['Yes', 'No'], n_samples),\n",
        "        'Dependents': np.random.choice(['0', '1', '2', '3+'], n_samples),\n",
        "        'Education': np.random.choice(['Graduate', 'Not Graduate'], n_samples),\n",
        "        'Self_Employed': np.random.choice(['Yes', 'No'], n_samples),\n",
        "        'ApplicantIncome': np.random.randint(1500, 81000, n_samples),\n",
        "        'CoapplicantIncome': np.random.randint(0, 50000, n_samples),\n",
        "        'LoanAmount': np.random.randint(9, 700, n_samples),\n",
        "        'Loan_Amount_Term': np.random.choice([12, 36, 60, 84, 120, 180, 240, 300, 360], n_samples),\n",
        "        'Credit_History': np.random.choice([0, 1], n_samples, p=[0.2, 0.8]),\n",
        "        'Property_Area': np.random.choice(['Urban', 'Rural', 'Semiurban'], n_samples),\n",
        "        'Loan_Status': np.random.choice(['Y', 'N'], n_samples, p=[0.7, 0.3])\n",
        "    }\n",
        "\n",
        "    df = pd.DataFrame(data)\n",
        "    print(\"‚úÖ Sample dataset created successfully!\")\n",
        "\n",
        "print(f\"\\nDataset shape: {df.shape}\")\n",
        "print(f\"Rows: {df.shape[0]}, Columns: {df.shape[1]}\")\n",
        "print(\"\\nFirst few rows:\")\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset Information:\n",
            "==================================================\n",
            "Total rows: 20000\n",
            "Total columns: 22\n",
            "\n",
            "Column names and data types:\n",
            "age                       int64\n",
            "gender                   object\n",
            "marital_status           object\n",
            "education_level          object\n",
            "annual_income           float64\n",
            "monthly_income          float64\n",
            "employment_status        object\n",
            "debt_to_income_ratio    float64\n",
            "credit_score              int64\n",
            "loan_amount             float64\n",
            "loan_purpose             object\n",
            "interest_rate           float64\n",
            "loan_term                 int64\n",
            "installment             float64\n",
            "grade_subgrade           object\n",
            "num_of_open_accounts      int64\n",
            "total_credit_limit      float64\n",
            "current_balance         float64\n",
            "delinquency_history       int64\n",
            "public_records            int64\n",
            "num_of_delinquencies      int64\n",
            "loan_paid_back            int64\n",
            "dtype: object\n",
            "\n",
            "==================================================\n",
            "\n",
            "Basic Statistics:\n",
            "                age  annual_income  monthly_income  debt_to_income_ratio  \\\n",
            "count  20000.000000   20000.000000    20000.000000          20000.000000   \n",
            "mean      48.027000   43549.637766     3629.136466              0.177019   \n",
            "std       15.829352   28668.579671     2389.048326              0.105059   \n",
            "min       21.000000    6000.000000      500.000000              0.010000   \n",
            "25%       35.000000   24260.752500     2021.730000              0.096000   \n",
            "50%       48.000000   36585.260000     3048.770000              0.160000   \n",
            "75%       62.000000   54677.917500     4556.495000              0.241000   \n",
            "max       75.000000  400000.000000    33333.330000              0.667000   \n",
            "\n",
            "       credit_score   loan_amount  interest_rate    loan_term   installment  \\\n",
            "count   20000.00000  20000.000000   20000.000000  20000.00000  20000.000000   \n",
            "mean      679.25695  15129.300909      12.400626     43.22280    455.625794   \n",
            "std        69.63858   8605.405513       2.442729     11.00838    274.622125   \n",
            "min       373.00000    500.000000       3.140000     36.00000      9.430000   \n",
            "25%       632.00000   8852.695000      10.740000     36.00000    253.910000   \n",
            "50%       680.00000  14946.170000      12.400000     36.00000    435.595000   \n",
            "75%       727.00000  20998.867500      14.002500     60.00000    633.595000   \n",
            "max       850.00000  49039.690000      22.510000     60.00000   1685.400000   \n",
            "\n",
            "       num_of_open_accounts  total_credit_limit  current_balance  \\\n",
            "count          20000.000000        20000.000000     20000.000000   \n",
            "mean               5.011800        48649.824769     24333.394631   \n",
            "std                2.244529        32423.378128     22313.845395   \n",
            "min                0.000000         6157.800000       496.350000   \n",
            "25%                3.000000        27180.492500      9592.572500   \n",
            "50%                5.000000        40241.615000     18334.555000   \n",
            "75%                6.000000        60361.257500     31743.327500   \n",
            "max               15.000000       454394.190000    352177.900000   \n",
            "\n",
            "       delinquency_history  public_records  num_of_delinquencies  \\\n",
            "count         20000.000000    20000.000000          20000.000000   \n",
            "mean              1.990150        0.061800              2.489150   \n",
            "std               1.474945        0.285105              1.631384   \n",
            "min               0.000000        0.000000              0.000000   \n",
            "25%               1.000000        0.000000              1.000000   \n",
            "50%               2.000000        0.000000              2.000000   \n",
            "75%               3.000000        0.000000              3.000000   \n",
            "max              11.000000        2.000000             11.000000   \n",
            "\n",
            "       loan_paid_back  \n",
            "count    20000.000000  \n",
            "mean         0.799900  \n",
            "std          0.400085  \n",
            "min          0.000000  \n",
            "25%          1.000000  \n",
            "50%          1.000000  \n",
            "75%          1.000000  \n",
            "max          1.000000  \n",
            "\n",
            "==================================================\n",
            "\n",
            "Missing values:\n",
            "age                     0\n",
            "gender                  0\n",
            "marital_status          0\n",
            "education_level         0\n",
            "annual_income           0\n",
            "monthly_income          0\n",
            "employment_status       0\n",
            "debt_to_income_ratio    0\n",
            "credit_score            0\n",
            "loan_amount             0\n",
            "loan_purpose            0\n",
            "interest_rate           0\n",
            "loan_term               0\n",
            "installment             0\n",
            "grade_subgrade          0\n",
            "num_of_open_accounts    0\n",
            "total_credit_limit      0\n",
            "current_balance         0\n",
            "delinquency_history     0\n",
            "public_records          0\n",
            "num_of_delinquencies    0\n",
            "loan_paid_back          0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Explore the dataset\n",
        "print(\"Dataset Information:\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"Total rows: {len(df)}\")\n",
        "print(f\"Total columns: {len(df.columns)}\")\n",
        "print(\"\\nColumn names and data types:\")\n",
        "print(df.dtypes)\n",
        "print(\"\\n\" + \"=\" * 50)\n",
        "print(\"\\nBasic Statistics:\")\n",
        "print(df.describe())\n",
        "print(\"\\n\" + \"=\" * 50)\n",
        "print(\"\\nMissing values:\")\n",
        "print(df.isnull().sum())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Creating Data Summary Function\n",
        "\n",
        "### Why Create a Summary?\n",
        "\n",
        "Instead of sending the entire dataset to the AI model (which would be expensive and hit token limits), we create a summary that includes:\n",
        "- Dataset dimensions\n",
        "- Column names and data types\n",
        "- Basic statistics (optional)\n",
        "\n",
        "This gives the AI agent enough context to understand the data structure and answer questions intelligently.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data Summary:\n",
            "============================================================\n",
            "The dataset has 20000 rows and 22 columns.\n",
            "\n",
            "Columns and their data types:\n",
            "- age (type: int64)\n",
            "- gender (type: object)\n",
            "- marital_status (type: object)\n",
            "- education_level (type: object)\n",
            "- annual_income (type: float64)\n",
            "- monthly_income (type: float64)\n",
            "- employment_status (type: object)\n",
            "- debt_to_income_ratio (type: float64)\n",
            "- credit_score (type: int64)\n",
            "- loan_amount (type: float64)\n",
            "- loan_purpose (type: object)\n",
            "- interest_rate (type: float64)\n",
            "- loan_term (type: int64)\n",
            "- installment (type: float64)\n",
            "- grade_subgrade (type: object)\n",
            "- num_of_open_accounts (type: int64)\n",
            "- total_credit_limit (type: float64)\n",
            "- current_balance (type: float64)\n",
            "- delinquency_history (type: int64)\n",
            "- public_records (type: int64)\n",
            "- num_of_delinquencies (type: int64)\n",
            "- loan_paid_back (type: int64)\n",
            "\n",
            "Numeric columns statistics:\n",
            "- age: min=21, max=75, mean=48.03\n",
            "- annual_income: min=6000.0, max=400000.0, mean=43549.64\n",
            "- monthly_income: min=500.0, max=33333.33, mean=3629.14\n",
            "- debt_to_income_ratio: min=0.01, max=0.667, mean=0.18\n",
            "- credit_score: min=373, max=850, mean=679.26\n",
            "\n",
            "Categorical columns sample values:\n",
            "- gender: Male, Female, Other\n",
            "- marital_status: Married, Single, Divorced, Widowed\n",
            "- education_level: Master's, Bachelor's, High School, Other, PhD\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def create_data_summary(df):\n",
        "    \"\"\"\n",
        "    Create a comprehensive summary of the dataset for the AI agent.\n",
        "    \n",
        "    Parameters:\n",
        "    -----------\n",
        "    df : pandas.DataFrame\n",
        "        The dataset to summarize\n",
        "    \n",
        "    Returns:\n",
        "    --------\n",
        "    str : A formatted string containing dataset summary\n",
        "    \"\"\"\n",
        "    summary = f\"The dataset has {df.shape[0]} rows and {df.shape[1]} columns.\\n\\n\"\n",
        "    \n",
        "    summary += \"Columns and their data types:\\n\"\n",
        "    for col in df.columns:\n",
        "        dtype = str(df[col].dtype)\n",
        "        summary += f\"- {col} (type: {dtype})\\n\"\n",
        "    \n",
        "    # Add some basic statistics for numeric columns\n",
        "    numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
        "    if len(numeric_cols) > 0:\n",
        "        summary += \"\\nNumeric columns statistics:\\n\"\n",
        "        for col in numeric_cols[:5]:  # Limit to first 5 numeric columns\n",
        "            summary += f\"- {col}: min={df[col].min()}, max={df[col].max()}, mean={df[col].mean():.2f}\\n\"\n",
        "    \n",
        "    # Add value counts for categorical columns\n",
        "    categorical_cols = df.select_dtypes(include=['object']).columns\n",
        "    if len(categorical_cols) > 0:\n",
        "        summary += \"\\nCategorical columns sample values:\\n\"\n",
        "        for col in categorical_cols[:3]:  # Limit to first 3 categorical columns\n",
        "            unique_vals = df[col].unique()[:5]  # First 5 unique values\n",
        "            summary += f\"- {col}: {', '.join(map(str, unique_vals))}\\n\"\n",
        "    \n",
        "    return summary\n",
        "\n",
        "# Test the summary function\n",
        "summary = create_data_summary(df)\n",
        "print(\"Data Summary:\")\n",
        "print(\"=\" * 60)\n",
        "print(summary)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Building the AI Agent\n",
        "\n",
        "### Understanding the AI Agent Function\n",
        "\n",
        "The AI agent function:\n",
        "1. Takes a user query and the dataset\n",
        "2. Creates a data summary\n",
        "3. Constructs a prompt with context and query\n",
        "4. Sends the prompt to OpenAI's GPT model\n",
        "5. Returns the model's response\n",
        "\n",
        "### Prompt Engineering Best Practices\n",
        "\n",
        "1. **Be Clear and Specific**: Clearly define the agent's role\n",
        "2. **Provide Context**: Give enough information for the model to understand\n",
        "3. **Set Expectations**: Tell the model how to structure its response\n",
        "4. **Use Examples**: Show the model what kind of output you want\n",
        "5. **Iterate**: Refine prompts based on results\n",
        "\n",
        "### Model Parameters Explained\n",
        "\n",
        "- **model**: Which GPT model to use (gpt-4o-mini, gpt-4o, gpt-3.5-turbo, etc.)\n",
        "- **temperature**: Controls randomness (0.0-2.0)\n",
        "  - 0.0-0.3: More deterministic, factual\n",
        "  - 0.4-0.7: Balanced\n",
        "  - 0.8-2.0: More creative, varied\n",
        "- **max_tokens**: Maximum length of response\n",
        "- **messages**: Conversation history (role: system/user/assistant)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "def ai_agent(user_query, df, model=\"gpt-4o-mini\", temperature=0.2, max_tokens=500):\n",
        "    \"\"\"\n",
        "    AI Agent function that processes user queries about the dataset.\n",
        "    \n",
        "    Parameters:\n",
        "    -----------\n",
        "    user_query : str\n",
        "        The user's question about the data\n",
        "    df : pandas.DataFrame\n",
        "        The dataset to analyze\n",
        "    model : str, optional\n",
        "        OpenAI model to use (default: \"gpt-4o-mini\")\n",
        "    temperature : float, optional\n",
        "        Model temperature (0.0-2.0), default 0.2 for more deterministic responses\n",
        "    max_tokens : int, optional\n",
        "        Maximum response length, default 500\n",
        "    \n",
        "    Returns:\n",
        "    --------\n",
        "    str : The AI agent's response\n",
        "    \"\"\"\n",
        "    # Create data summary\n",
        "    data_context = create_data_summary(df)\n",
        "    \n",
        "    # Construct the prompt\n",
        "    prompt = f\"\"\"You are a data expert AI agent specialized in analyzing structured datasets.\n",
        "\n",
        "You have been provided with this dataset summary:\n",
        "{data_context}\n",
        "\n",
        "Now, based on the user's question:\n",
        "'{user_query}'\n",
        "\n",
        "Instructions:\n",
        "1. Think step-by-step about how to answer this question\n",
        "2. Assume you can access and analyze the dataset like a Data Scientist would using Pandas\n",
        "3. Consider what columns and operations would be needed\n",
        "4. Provide a clear, concise, and accurate answer\n",
        "5. If the question cannot be answered with the available data, explain why\n",
        "\n",
        "Give a clear, final answer with your reasoning.\"\"\"\n",
        "    \n",
        "    try:\n",
        "        # Make API call to OpenAI\n",
        "        response = client.chat.completions.create(\n",
        "            model=model,\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are a helpful data analysis assistant.\"},\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ],\n",
        "            temperature=temperature,\n",
        "            max_tokens=max_tokens\n",
        "        )\n",
        "        \n",
        "        # Extract the answer\n",
        "        answer = response.choices[0].message.content\n",
        "        return answer\n",
        "    \n",
        "    except Exception as e:\n",
        "        return f\"Error: {str(e)}. Please check your API key and connection.\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing AI Agent...\n",
            "============================================================\n",
            "Query: What is the average loan amount?\n",
            "\n",
            "Response:\n",
            "To answer the question \"What is the average loan amount?\", we can follow these steps:\n",
            "\n",
            "1. **Identify the Relevant Column**: The question specifically asks about the loan amount, which corresponds to the `loan_amount` column in the dataset.\n",
            "\n",
            "2. **Understand the Data Type**: The `loan_amount` column is of type `float64`, which means it contains numerical values that can be used for calculations.\n",
            "\n",
            "3. **Calculate the Average**: To find the average loan amount, we will sum all the values in the `loan_amount` column and then divide by the number of entries (rows) in that column.\n",
            "\n",
            "4. **Use Pandas for Calculation**: Assuming we have access to the dataset as a Pandas DataFrame, we can use the following code snippet to calculate the average loan amount:\n",
            "\n",
            "   ```python\n",
            "   average_loan_amount = df['loan_amount'].mean()\n",
            "   ```\n",
            "\n",
            "5. **Final Answer**: Since the dataset summary does not provide the average loan amount directly, we would need to perform the calculation as described above. However, if we assume the dataset is well-formed and contains valid entries, we can conclude that the average loan amount can be computed using the method outlined.\n",
            "\n",
            "Since the dataset summary does not provide the average loan amount directly, we cannot provide a numerical answer without performing the calculation. However, the process to find it is clear and straightforward.\n",
            "\n",
            "**Final Answer**: The average loan amount can be calculated using the mean of the `loan_amount` column in the dataset. The exact value requires computation from the dataset.\n"
          ]
        }
      ],
      "source": [
        "# Test the AI agent with a sample query\n",
        "print(\"Testing AI Agent...\")\n",
        "print(\"=\" * 60)\n",
        "test_query = \"What is the average loan amount?\"\n",
        "# Uncomment below line to run the agent\n",
        "# response = ai_agent(test_query, df, model=\"gpt-4o-mini\")\n",
        "# print(f\"Query: {test_query}\")\n",
        "# print(f\"\\nResponse:\\n{response}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "def interactive_agent(df):\n",
        "    \"\"\"\n",
        "    Interactive loop for querying the AI agent.\n",
        "    \n",
        "    Parameters:\n",
        "    -----------\n",
        "    df : pandas.DataFrame\n",
        "        The dataset to query\n",
        "    \"\"\"\n",
        "    print(\"=\" * 60)\n",
        "    print(\"Welcome to Loan Review AI Agent!\")\n",
        "    print(\"=\" * 60)\n",
        "    print(\"You can ask anything about the loan applicants data.\")\n",
        "    print(\"Type 'exit' or 'quit' to end the session.\")\n",
        "    print(\"Type 'help' for example questions.\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    while True:\n",
        "        user_input = input(\"\\nüí¨ Your question: \").strip()\n",
        "        \n",
        "        if not user_input:\n",
        "            print(\"Please enter a question.\")\n",
        "            continue\n",
        "        \n",
        "        if user_input.lower() in ['exit', 'quit', 'q']:\n",
        "            print(\"\\nüëã Thank you for using the AI Agent. Goodbye!\")\n",
        "            break\n",
        "        \n",
        "        if user_input.lower() == 'help':\n",
        "            print(\"\\nüìù Example questions you can ask:\")\n",
        "            print(\"  - What is the average loan amount?\")\n",
        "            print(\"  - How many applicants are self-employed?\")\n",
        "            print(\"  - What is the highest applicant income?\")\n",
        "            print(\"  - How many loans were approved?\")\n",
        "            print(\"  - What is the distribution of property areas?\")\n",
        "            continue\n",
        "        \n",
        "        print(\"\\nü§î Processing your question...\")\n",
        "        try:\n",
        "            response = ai_agent(user_input, df)\n",
        "            print(\"\\nü§ñ AI Agent Response:\")\n",
        "            print(\"-\" * 60)\n",
        "            print(response)\n",
        "            print(\"-\" * 60)\n",
        "        except Exception as e:\n",
        "            print(f\"\\n‚ùå Error: {e}\")\n",
        "            print(\"Please try again or check your API configuration.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "Welcome to Loan Review AI Agent!\n",
            "============================================================\n",
            "You can ask anything about the loan applicants data.\n",
            "Type 'exit' or 'quit' to end the session.\n",
            "Type 'help' for example questions.\n",
            "============================================================\n",
            "\n",
            "ü§î Processing your question...\n",
            "\n",
            "ü§ñ AI Agent Response:\n",
            "------------------------------------------------------------\n",
            "To answer the question \"how many loans are approved?\", we need to identify the relevant column in the dataset that indicates whether a loan has been approved or not. \n",
            "\n",
            "### Step-by-Step Analysis:\n",
            "\n",
            "1. **Identify Relevant Column**: \n",
            "   - The dataset summary includes a column named `loan_paid_back`, which likely indicates whether a loan was successfully paid back. However, it does not explicitly state whether this column directly correlates with loan approval. Typically, a loan that is paid back would imply that it was approved, but we need to confirm this assumption.\n",
            "\n",
            "2. **Understanding the `loan_paid_back` Column**:\n",
            "   - We need to check the values in the `loan_paid_back` column. If it is a binary indicator (e.g., 1 for approved and 0 for not approved), we can use it to count the number of approved loans.\n",
            "\n",
            "3. **Count Approved Loans**:\n",
            "   - If `loan_paid_back` is indeed a binary indicator, we can use a simple aggregation to count the number of loans that have been paid back (i.e., approved).\n",
            "\n",
            "### Operations Needed:\n",
            "- Use Pandas to filter the dataset based on the `loan_paid_back` column.\n",
            "- Count the number of entries where `loan_paid_back` equals 1 (assuming 1 indicates an approved loan).\n",
            "\n",
            "### Example Code:\n",
            "If we were to write the code to perform this operation, it would look something like this:\n",
            "\n",
            "```python\n",
            "import pandas as pd\n",
            "\n",
            "# Assuming df is the DataFrame containing the dataset\n",
            "approved_loans_count = df[df['loan_paid_back'] == 1].shape[0]\n",
            "```\n",
            "\n",
            "### Final Answer:\n",
            "Assuming that the `loan_paid_back` column indicates loan approval, the number of loans that are approved can be determined by counting the entries where `loan_paid_back` equals 1. \n",
            "\n",
            "If the `loan_paid_back` column is not a binary indicator or does not correlate with loan approval, we would need additional information to accurately answer the question.\n",
            "\n",
            "Thus, based on the assumption that `loan_paid_back` indicates loan approval, the final answer would be:\n",
            "\n",
            "**The number of approved loans is equal to the count of entries in the `loan_paid_back` column where the value is 1.** \n",
            "\n",
            "If you have access to the dataset, you can run the provided code snippet to get the exact count.\n",
            "------------------------------------------------------------\n",
            "\n",
            "üëã Thank you for using the AI Agent. Goodbye!\n"
          ]
        }
      ],
      "source": [
        "# Uncomment to run interactive session\n",
        "# interactive_agent(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Testing and Examples\n",
        "\n",
        "Let's test the AI agent with various types of questions to see how it handles different query patterns.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example 1: Statistical Question\n",
        "print(\"Example 1: Statistical Analysis\")\n",
        "print(\"=\" * 60)\n",
        "query1 = \"What is the average loan amount applied for by all applicants?\"\n",
        "print(f\"Query: {query1}\\n\")\n",
        "response1 = ai_agent(query1, df)\n",
        "print(f\"Response: {response1}\\n\")\n",
        "\n",
        "# Verify with actual calculation\n",
        "actual_avg = df['LoanAmount'].mean()\n",
        "print(f\"Actual average (for verification): {actual_avg:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example 2: Maximum Value Question\n",
        "print(\"Example 2: Finding Maximum Value\")\n",
        "print(\"=\" * 60)\n",
        "query2 = \"Who has the highest applicant income?\"\n",
        "print(f\"Query: {query2}\\n\")\n",
        "response2 = ai_agent(query2, df)\n",
        "print(f\"Response: {response2}\\n\")\n",
        "\n",
        "# Verify with actual calculation\n",
        "max_income = df['ApplicantIncome'].max()\n",
        "max_income_row = df[df['ApplicantIncome'] == max_income]\n",
        "print(f\"Actual maximum income (for verification): {max_income}\")\n",
        "print(f\"Loan ID with max income: {max_income_row['Loan_ID'].values[0]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example 3: Counting/Filtering Question\n",
        "print(\"Example 3: Counting Records\")\n",
        "print(\"=\" * 60)\n",
        "query3 = \"How many applicants are self-employed?\"\n",
        "print(f\"Query: {query3}\\n\")\n",
        "response3 = ai_agent(query3, df)\n",
        "print(f\"Response: {response3}\\n\")\n",
        "\n",
        "# Verify with actual calculation\n",
        "self_employed_count = len(df[df['Self_Employed'] == 'Yes'])\n",
        "print(f\"Actual count (for verification): {self_employed_count}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example 4: Conditional Analysis\n",
        "print(\"Example 4: Conditional Analysis\")\n",
        "print(\"=\" * 60)\n",
        "query4 = \"How many loans were approved?\"\n",
        "print(f\"Query: {query4}\\n\")\n",
        "response4 = ai_agent(query4, df)\n",
        "print(f\"Response: {response4}\\n\")\n",
        "\n",
        "# Verify with actual calculation\n",
        "approved_count = len(df[df['Loan_Status'] == 'Y'])\n",
        "print(f\"Actual approved loans (for verification): {approved_count}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example 5: Distribution Question\n",
        "print(\"Example 5: Distribution Analysis\")\n",
        "print(\"=\" * 60)\n",
        "query5 = \"What is the distribution of property areas in the dataset?\"\n",
        "print(f\"Query: {query5}\\n\")\n",
        "response5 = ai_agent(query5, df)\n",
        "print(f\"Response: {response5}\\n\")\n",
        "\n",
        "# Verify with actual calculation\n",
        "property_dist = df['Property_Area'].value_counts()\n",
        "print(f\"Actual distribution (for verification):\\n{property_dist}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Advanced Features\n",
        "\n",
        "### Enhanced AI Agent with Better Error Handling\n",
        "\n",
        "Let's create an improved version of the AI agent with:\n",
        "- Better error handling\n",
        "- Response validation\n",
        "- Cost tracking\n",
        "- Response caching (optional)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def enhanced_ai_agent(user_query, df, model=\"gpt-4o\", temperature=0.2, max_tokens=500, verbose=True):\n",
        "    \"\"\"\n",
        "    Enhanced AI Agent with better error handling and response tracking.\n",
        "    \n",
        "    Parameters:\n",
        "    -----------\n",
        "    user_query : str\n",
        "        The user's question about the data\n",
        "    df : pandas.DataFrame\n",
        "        The dataset to analyze\n",
        "    model : str, optional\n",
        "        OpenAI model to use\n",
        "    temperature : float, optional\n",
        "        Model temperature\n",
        "    max_tokens : int, optional\n",
        "        Maximum response length\n",
        "    verbose : bool, optional\n",
        "        Whether to print additional information\n",
        "    \n",
        "    Returns:\n",
        "    --------\n",
        "    dict : Dictionary containing response, metadata, and error info\n",
        "    \"\"\"\n",
        "    data_context = create_data_summary(df)\n",
        "    \n",
        "    prompt = f\"\"\"You are a data expert AI agent specialized in analyzing structured datasets.\n",
        "\n",
        "You have been provided with this dataset summary:\n",
        "{data_context}\n",
        "\n",
        "Now, based on the user's question:\n",
        "'{user_query}'\n",
        "\n",
        "Instructions:\n",
        "1. Think step-by-step about how to answer this question\n",
        "2. Assume you can access and analyze the dataset like a Data Scientist would using Pandas\n",
        "3. Consider what columns and operations would be needed\n",
        "4. Provide a clear, concise, and accurate answer\n",
        "5. If the question cannot be answered with the available data, explain why\n",
        "\n",
        "Give a clear, final answer with your reasoning.\"\"\"\n",
        "    \n",
        "    result = {\n",
        "        'query': user_query,\n",
        "        'response': None,\n",
        "        'error': None,\n",
        "        'tokens_used': None,\n",
        "        'model_used': model,\n",
        "        'success': False\n",
        "    }\n",
        "    \n",
        "    try:\n",
        "        response = client.chat.completions.create(\n",
        "            model=model,\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are a helpful data analysis assistant.\"},\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ],\n",
        "            temperature=temperature,\n",
        "            max_tokens=max_tokens\n",
        "        )\n",
        "        \n",
        "        result['response'] = response.choices[0].message.content\n",
        "        result['tokens_used'] = response.usage.total_tokens\n",
        "        result['success'] = True\n",
        "        \n",
        "        if verbose:\n",
        "            print(f\"‚úÖ Query processed successfully\")\n",
        "            print(f\"üìä Tokens used: {result['tokens_used']}\")\n",
        "            print(f\"ü§ñ Model: {result['model_used']}\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        result['error'] = str(e)\n",
        "        result['response'] = f\"Error processing query: {str(e)}\"\n",
        "        \n",
        "        if verbose:\n",
        "            print(f\"‚ùå Error: {e}\")\n",
        "    \n",
        "    return result\n",
        "\n",
        "# Test the enhanced agent\n",
        "print(\"Testing Enhanced AI Agent\")\n",
        "print(\"=\" * 60)\n",
        "test_result = enhanced_ai_agent(\"What is the average applicant income?\", df)\n",
        "print(f\"\\nQuery: {test_result['query']}\")\n",
        "print(f\"\\nResponse:\\n{test_result['response']}\")\n",
        "print(f\"\\nMetadata: {test_result}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def analyze_data(query, df):\n",
        "    \"\"\"\n",
        "    Perform basic data analysis based on common query patterns.\n",
        "    This function attempts to extract the answer from the data directly.\n",
        "    \"\"\"\n",
        "    query_lower = query.lower()\n",
        "    \n",
        "    # Pattern matching for common queries\n",
        "    if 'average' in query_lower and 'loan' in query_lower and 'amount' in query_lower:\n",
        "        return f\"The average loan amount is {df['LoanAmount'].mean():.2f}\"\n",
        "    \n",
        "    elif 'highest' in query_lower or 'maximum' in query_lower:\n",
        "        if 'income' in query_lower:\n",
        "            max_val = df['ApplicantIncome'].max()\n",
        "            return f\"The highest applicant income is {max_val}\"\n",
        "        elif 'loan' in query_lower:\n",
        "            max_val = df['LoanAmount'].max()\n",
        "            return f\"The highest loan amount is {max_val}\"\n",
        "    \n",
        "    elif 'how many' in query_lower or 'count' in query_lower:\n",
        "        if 'self-employed' in query_lower or 'self employed' in query_lower:\n",
        "            count = len(df[df['Self_Employed'] == 'Yes'])\n",
        "            return f\"There are {count} self-employed applicants\"\n",
        "        elif 'approved' in query_lower:\n",
        "            count = len(df[df['Loan_Status'] == 'Y'])\n",
        "            return f\"There are {count} approved loans\"\n",
        "    \n",
        "    return None  # Could not extract answer automatically\n",
        "\n",
        "def hybrid_ai_agent(user_query, df):\n",
        "    \"\"\"\n",
        "    Hybrid approach: Try to get answer from data first, then use AI for explanation.\n",
        "    \"\"\"\n",
        "    # Try to get direct answer\n",
        "    direct_answer = analyze_data(user_query, df)\n",
        "    \n",
        "    data_context = create_data_summary(df)\n",
        "    \n",
        "    if direct_answer:\n",
        "        prompt = f\"\"\"You are a data expert AI agent.\n",
        "\n",
        "Dataset summary:\n",
        "{data_context}\n",
        "\n",
        "The user asked: '{user_query}'\n",
        "\n",
        "Based on data analysis, the answer is: {direct_answer}\n",
        "\n",
        "Please provide a clear, natural language explanation of this result.\"\"\"\n",
        "    else:\n",
        "        prompt = f\"\"\"You are a data expert AI agent.\n",
        "\n",
        "Dataset summary:\n",
        "{data_context}\n",
        "\n",
        "User question: '{user_query}'\n",
        "\n",
        "Think step-by-step and provide a clear answer.\"\"\"\n",
        "    \n",
        "    try:\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-4o-mini\",\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "            temperature=0.2,\n",
        "            max_tokens=500\n",
        "        )\n",
        "        return response.choices[0].message.content\n",
        "    except Exception as e:\n",
        "        return f\"Error: {str(e)}\"\n",
        "\n",
        "# Test hybrid approach\n",
        "print(\"Testing Hybrid AI Agent\")\n",
        "print(\"=\" * 60)\n",
        "hybrid_response = hybrid_ai_agent(\"What is the average loan amount?\", df)\n",
        "print(f\"Response: {hybrid_response}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import time\n",
        "from openai import APIError, RateLimitError, APIConnectionError\n",
        "\n",
        "def robust_ai_agent(user_query, df, model=\"gpt-4o\", temperature=0.2, max_tokens=500, max_retries=3):\n",
        "    \"\"\"\n",
        "    Robust AI Agent with comprehensive error handling.\n",
        "    \n",
        "    Parameters:\n",
        "    -----------\n",
        "    user_query : str\n",
        "        The user's question\n",
        "    df : pandas.DataFrame\n",
        "        The dataset\n",
        "    model : str\n",
        "        Model to use\n",
        "    temperature : float\n",
        "        Temperature setting\n",
        "    max_tokens : int\n",
        "        Maximum tokens\n",
        "    max_retries : int\n",
        "        Maximum retry attempts for transient errors\n",
        "    \n",
        "    Returns:\n",
        "    --------\n",
        "    dict : Response with status and message\n",
        "    \"\"\"\n",
        "    # Validate inputs\n",
        "    if not user_query or not user_query.strip():\n",
        "        return {\n",
        "            'success': False,\n",
        "            'response': 'Please provide a valid question.',\n",
        "            'error_type': 'invalid_input'\n",
        "        }\n",
        "    \n",
        "    if df.empty:\n",
        "        return {\n",
        "            'success': False,\n",
        "            'response': 'The dataset is empty. Cannot answer questions.',\n",
        "            'error_type': 'empty_dataset'\n",
        "        }\n",
        "    \n",
        "    data_context = create_data_summary(df)\n",
        "    \n",
        "    prompt = f\"\"\"You are a data expert AI agent.\n",
        "\n",
        "Dataset summary:\n",
        "{data_context}\n",
        "\n",
        "User question: '{user_query}'\n",
        "\n",
        "Provide a clear, step-by-step answer. If the question cannot be answered with the available data, explain why.\"\"\"\n",
        "    \n",
        "    # Retry logic for transient errors\n",
        "    for attempt in range(max_retries):\n",
        "        try:\n",
        "            response = client.chat.completions.create(\n",
        "                model=model,\n",
        "                messages=[\n",
        "                    {\"role\": \"system\", \"content\": \"You are a helpful data analysis assistant.\"},\n",
        "                    {\"role\": \"user\", \"content\": prompt}\n",
        "                ],\n",
        "                temperature=temperature,\n",
        "                max_tokens=max_tokens\n",
        "            )\n",
        "            \n",
        "            return {\n",
        "                'success': True,\n",
        "                'response': response.choices[0].message.content,\n",
        "                'tokens_used': response.usage.total_tokens,\n",
        "                'model': model,\n",
        "                'attempt': attempt + 1\n",
        "            }\n",
        "        \n",
        "        except RateLimitError as e:\n",
        "            wait_time = 2 ** attempt  # Exponential backoff\n",
        "            if attempt < max_retries - 1:\n",
        "                print(f\"‚ö†Ô∏è Rate limit hit. Waiting {wait_time} seconds before retry...\")\n",
        "                time.sleep(wait_time)\n",
        "                continue\n",
        "            else:\n",
        "                return {\n",
        "                    'success': False,\n",
        "                    'response': 'Rate limit exceeded. Please try again later.',\n",
        "                    'error_type': 'rate_limit',\n",
        "                    'error': str(e)\n",
        "                }\n",
        "        \n",
        "        except APIConnectionError as e:\n",
        "            wait_time = 2 ** attempt\n",
        "            if attempt < max_retries - 1:\n",
        "                print(f\"‚ö†Ô∏è Connection error. Retrying in {wait_time} seconds...\")\n",
        "                time.sleep(wait_time)\n",
        "                continue\n",
        "            else:\n",
        "                return {\n",
        "                    'success': False,\n",
        "                    'response': 'Connection error. Please check your internet connection.',\n",
        "                    'error_type': 'connection_error',\n",
        "                    'error': str(e)\n",
        "                }\n",
        "        \n",
        "        except APIError as e:\n",
        "            error_code = getattr(e, 'code', None)\n",
        "            if error_code == 'invalid_api_key':\n",
        "                return {\n",
        "                    'success': False,\n",
        "                    'response': 'Invalid API key. Please check your OpenAI API key.',\n",
        "                    'error_type': 'authentication_error',\n",
        "                    'error': str(e)\n",
        "                }\n",
        "            elif error_code == 'insufficient_quota':\n",
        "                return {\n",
        "                    'success': False,\n",
        "                    'response': 'Insufficient API quota. Please check your OpenAI account.',\n",
        "                    'error_type': 'quota_error',\n",
        "                    'error': str(e)\n",
        "                }\n",
        "            else:\n",
        "                return {\n",
        "                    'success': False,\n",
        "                    'response': f'API error: {str(e)}',\n",
        "                    'error_type': 'api_error',\n",
        "                    'error': str(e)\n",
        "                }\n",
        "        \n",
        "        except Exception as e:\n",
        "            return {\n",
        "                'success': False,\n",
        "                'response': f'Unexpected error: {str(e)}',\n",
        "                'error_type': 'unknown_error',\n",
        "                'error': str(e)\n",
        "            }\n",
        "    \n",
        "    return {\n",
        "        'success': False,\n",
        "        'response': 'Failed after multiple retry attempts.',\n",
        "        'error_type': 'max_retries_exceeded'\n",
        "    }\n",
        "\n",
        "# Test error handling\n",
        "print(\"Testing Robust AI Agent\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Test with valid query\n",
        "result1 = robust_ai_agent(\"What is the average loan amount?\", df)\n",
        "print(f\"Valid query result: {result1['success']}\")\n",
        "if result1['success']:\n",
        "    print(f\"Response: {result1['response'][:100]}...\")\n",
        "\n",
        "# Test with empty query\n",
        "result2 = robust_ai_agent(\"\", df)\n",
        "print(f\"\\nEmpty query result: {result2}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Understanding 429 Quota Errors\n",
        "\n",
        "### The Confusion: Budget vs. Quota vs. Rate Limits\n",
        "\n",
        "If you're seeing a **429 error** saying \"You exceeded your current quota\" but your dashboard shows **$0 used out of $5 budgeted**, you're encountering a common confusion between different types of limits:\n",
        "\n",
        "#### 1. **Account Budget** (What you see in Dashboard)\n",
        "- This is your **spending limit** (e.g., $5 for January)\n",
        "- Shows how much money you've spent\n",
        "- This is **NOT** the same as quota\n",
        "\n",
        "#### 2. **API Quota** (What causes 429 errors)\n",
        "- This is a **usage limit** separate from budget\n",
        "- Can be related to:\n",
        "  - **Account tier** (free tier has lower quotas)\n",
        "  - **Payment method** (accounts without valid payment may have restricted quotas)\n",
        "  - **Model-specific limits** (newer models like gpt-4o may have stricter quotas)\n",
        "  - **Rate limits** (requests per minute/hour)\n",
        "\n",
        "#### 3. **Rate Limits** (Requests per time period)\n",
        "- How many requests you can make per minute/hour/day\n",
        "- Different for each model\n",
        "- Separate from quota and budget\n",
        "\n",
        "### Common Causes of 429 \"Quota Exceeded\" Errors\n",
        "\n",
        "1. **No Payment Method Added**\n",
        "   - Even with a budget set, if no payment method is on file, quotas are very limited\n",
        "   - **Solution**: Add a payment method in OpenAI dashboard ‚Üí Billing ‚Üí Payment methods\n",
        "\n",
        "2. **Free Tier Limitations**\n",
        "   - Free tier accounts have very low quotas\n",
        "   - **Solution**: Upgrade to a paid plan\n",
        "\n",
        "3. **Model-Specific Quotas**\n",
        "   - Some models (especially newer ones like gpt-4o) have stricter quotas\n",
        "   - **Solution**: Try using `gpt-3.5-turbo` which has higher quotas\n",
        "\n",
        "4. **Rate Limiting**\n",
        "   - Too many requests too quickly\n",
        "   - **Solution**: Add delays between requests, use exponential backoff\n",
        "\n",
        "5. **Account Verification Issues**\n",
        "   - Unverified accounts have lower quotas\n",
        "   - **Solution**: Complete account verification\n",
        "\n",
        "### How to Fix 429 Quota Errors\n",
        "\n",
        "#### Step 1: Check Your Account Status\n",
        "1. Go to: https://platform.openai.com/account/usage\n",
        "2. Check if you have a payment method added\n",
        "3. Verify your account is fully set up\n",
        "\n",
        "#### Step 2: Add Payment Method (If Missing)\n",
        "1. Go to: https://platform.openai.com/account/billing/payment-methods\n",
        "2. Add a credit card or other payment method\n",
        "3. Even if you have a budget, a payment method is often required for higher quotas\n",
        "\n",
        "#### Step 3: Check Rate Limits\n",
        "1. Go to: https://platform.openai.com/account/rate-limits\n",
        "2. See your current rate limits for each model\n",
        "3. Adjust your code to respect these limits\n",
        "\n",
        "#### Step 4: Use a Different Model (Temporary Fix)\n",
        "If you need to continue working immediately, switch to a model with higher quotas:\n",
        "\n",
        "```python\n",
        "# Instead of gpt-4o, use gpt-3.5-turbo which has higher quotas\n",
        "response = ai_agent(query, df, model=\"gpt-3.5-turbo\")\n",
        "```\n",
        "\n",
        "#### Step 5: Implement Rate Limiting in Your Code\n",
        "Add delays between requests to avoid hitting rate limits:\n",
        "\n",
        "```python\n",
        "import time\n",
        "\n",
        "def rate_limited_agent(query, df, delay=1):\n",
        "    \"\"\"Agent with built-in rate limiting.\"\"\"\n",
        "    time.sleep(delay)  # Wait between requests\n",
        "    return ai_agent(query, df)\n",
        "```\n",
        "\n",
        "### Quick Diagnostic Function\n",
        "\n",
        "Use this function to check your account status:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def diagnose_quota_issue():\n",
        "    \"\"\"\n",
        "    Diagnostic function to help identify quota/rate limit issues.\n",
        "    \"\"\"\n",
        "    print(\"üîç Diagnosing OpenAI API Quota Issues...\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    try:\n",
        "        # Test 1: Check if API key is set\n",
        "        api_key = os.getenv('OPENAI_API_KEY')\n",
        "        if not api_key:\n",
        "            print(\"‚ùå API key not found\")\n",
        "            return\n",
        "        \n",
        "        print(\"‚úÖ API key found\")\n",
        "        \n",
        "        # Test 2: Try a simple request with gpt-3.5-turbo (usually has higher quotas)\n",
        "        print(\"\\nüìä Testing with gpt-3.5-turbo (higher quota model)...\")\n",
        "        try:\n",
        "            test_client = OpenAI(api_key=api_key)\n",
        "            response = test_client.chat.completions.create(\n",
        "                model=\"gpt-3.5-turbo\",\n",
        "                messages=[{\"role\": \"user\", \"content\": \"Say 'test'\"}],\n",
        "                max_tokens=5\n",
        "            )\n",
        "            print(\"‚úÖ gpt-3.5-turbo works! Your account has quota for this model.\")\n",
        "            print(\"üí° Tip: Use gpt-3.5-turbo instead of gpt-4o if you're hitting quota limits\")\n",
        "        except Exception as e:\n",
        "            error_str = str(e)\n",
        "            if '429' in error_str or 'quota' in error_str.lower() or 'rate_limit' in error_str.lower():\n",
        "                print(\"‚ùå Quota/Rate limit error detected\")\n",
        "                print(f\"   Error: {error_str[:200]}\")\n",
        "                print(\"\\nüîß Solutions:\")\n",
        "                print(\"   1. Add a payment method: https://platform.openai.com/account/billing/payment-methods\")\n",
        "                print(\"   2. Check rate limits: https://platform.openai.com/account/rate-limits\")\n",
        "                print(\"   3. Wait a few minutes and try again\")\n",
        "                print(\"   4. Use gpt-3.5-turbo instead of gpt-4o\")\n",
        "            else:\n",
        "                print(f\"‚ùå Other error: {e}\")\n",
        "        \n",
        "        # Test 3: Try with gpt-4o (if gpt-3.5-turbo worked)\n",
        "        print(\"\\nüìä Testing with gpt-4o (may have stricter quotas)...\")\n",
        "        try:\n",
        "            response = test_client.chat.completions.create(\n",
        "                model=\"gpt-4o\",\n",
        "                messages=[{\"role\": \"user\", \"content\": \"Say 'test'\"}],\n",
        "                max_tokens=5\n",
        "            )\n",
        "            print(\"‚úÖ gpt-4o also works!\")\n",
        "        except Exception as e:\n",
        "            error_str = str(e)\n",
        "            if '429' in error_str or 'quota' in error_str.lower():\n",
        "                print(\"‚ö†Ô∏è  gpt-4o has quota restrictions\")\n",
        "                print(\"üí° Use gpt-3.5-turbo for now, or add payment method for higher gpt-4o quotas\")\n",
        "            else:\n",
        "                print(f\"‚ùå Error with gpt-4o: {e}\")\n",
        "        \n",
        "        print(\"\\n\" + \"=\" * 60)\n",
        "        print(\"üìù Next Steps:\")\n",
        "        print(\"   1. Visit: https://platform.openai.com/account/usage\")\n",
        "        print(\"   2. Check: https://platform.openai.com/account/rate-limits\")\n",
        "        print(\"   3. Ensure payment method is added\")\n",
        "        print(\"   4. Consider using gpt-3.5-turbo for development\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Diagnostic failed: {e}\")\n",
        "\n",
        "# Uncomment to run diagnostic\n",
        "# diagnose_quota_issue()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Utility function to test API connection\n",
        "def test_openai_connection():\n",
        "    \"\"\"Test if OpenAI API is properly configured.\"\"\"\n",
        "    print(\"Testing OpenAI API Connection...\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    try:\n",
        "        # Test 1: Check API key\n",
        "        api_key = os.getenv('OPENAI_API_KEY')\n",
        "        if not api_key:\n",
        "            print(\"‚ùå API key not found in environment variables\")\n",
        "            return False\n",
        "        print(f\"‚úÖ API key found (length: {len(api_key)})\")\n",
        "        \n",
        "        # Test 2: Initialize client\n",
        "        client = OpenAI(api_key=api_key)\n",
        "        print(\"‚úÖ OpenAI client initialized\")\n",
        "        \n",
        "        # Test 3: List available models\n",
        "        try:\n",
        "            models = client.models.list()\n",
        "            print(f\"‚úÖ Can access models API ({len(list(models))} models available)\")\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è Could not list models: {e}\")\n",
        "        \n",
        "        # Test 4: Simple completion\n",
        "        try:\n",
        "            response = client.chat.completions.create(\n",
        "                model=\"gpt-3.5-turbo\",\n",
        "                messages=[{\"role\": \"user\", \"content\": \"Say 'test successful' if you can read this.\"}],\n",
        "                max_tokens=10\n",
        "            )\n",
        "            print(f\"‚úÖ Test completion successful: {response.choices[0].message.content}\")\n",
        "            return True\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Test completion failed: {e}\")\n",
        "            return False\n",
        "            \n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Connection test failed: {e}\")\n",
        "        return False\n",
        "\n",
        "# Uncomment to run connection test\n",
        "# test_openai_connection()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exercises\n",
        "\n",
        "### Exercise 1: Basic Agent Setup\n",
        "\n",
        "**Task**: Set up your OpenAI API key and test a simple query.\n",
        "\n",
        "**Steps**:\n",
        "1. Get your OpenAI API key\n",
        "2. Set it up using environment variables or .env file\n",
        "3. Test the connection using the `test_openai_connection()` function\n",
        "4. Run a simple query: \"What columns are in the dataset?\"\n",
        "\n",
        "**Expected Output**: A response describing the dataset columns.\n",
        "\n",
        "---\n",
        "\n",
        "### Exercise 2: Custom Query Function\n",
        "\n",
        "**Task**: Create a function that asks the AI agent a question and prints the response nicely formatted.\n",
        "\n",
        "**Requirements**:\n",
        "- Function should take a query string as input\n",
        "- Format the output with clear separators\n",
        "- Include the query and response\n",
        "- Handle errors gracefully\n",
        "\n",
        "**Template**:\n",
        "```python\n",
        "def ask_question(query):\n",
        "    # Your code here\n",
        "    pass\n",
        "\n",
        "# Test it\n",
        "ask_question(\"How many rows are in the dataset?\")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### Exercise 3: Batch Questions\n",
        "\n",
        "**Task**: Create a function that processes multiple questions at once.\n",
        "\n",
        "**Requirements**:\n",
        "- Accept a list of questions\n",
        "- Process each question\n",
        "- Return a dictionary mapping questions to answers\n",
        "- Include error handling\n",
        "\n",
        "**Template**:\n",
        "```python\n",
        "def batch_questions(questions_list, df):\n",
        "    # Your code here\n",
        "    pass\n",
        "\n",
        "# Test it\n",
        "questions = [\n",
        "    \"What is the average loan amount?\",\n",
        "    \"How many applicants are graduates?\",\n",
        "    \"What percentage of loans were approved?\"\n",
        "]\n",
        "results = batch_questions(questions, df)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### Exercise 4: Enhanced Data Summary\n",
        "\n",
        "**Task**: Improve the `create_data_summary()` function to include more detailed statistics.\n",
        "\n",
        "**Requirements**:\n",
        "- Add missing value counts\n",
        "- Include unique value counts for categorical columns\n",
        "- Add correlation information for numeric columns\n",
        "- Make it more informative for the AI agent\n",
        "\n",
        "---\n",
        "\n",
        "### Exercise 5: Query Validation\n",
        "\n",
        "**Task**: Create a function that validates user queries before sending to the AI.\n",
        "\n",
        "**Requirements**:\n",
        "- Check if query is empty\n",
        "- Check if query is too long (e.g., > 500 characters)\n",
        "- Detect potentially harmful queries\n",
        "- Provide helpful error messages\n",
        "\n",
        "**Template**:\n",
        "```python\n",
        "def validate_query(query):\n",
        "    # Your validation logic\n",
        "    # Return (is_valid, error_message)\n",
        "    pass\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### Exercise 6: Response Caching\n",
        "\n",
        "**Task**: Implement a simple caching mechanism to avoid redundant API calls.\n",
        "\n",
        "**Requirements**:\n",
        "- Cache responses for identical queries\n",
        "- Use a dictionary to store query-response pairs\n",
        "- Add a function to clear cache\n",
        "- Optional: Add cache expiration\n",
        "\n",
        "**Template**:\n",
        "```python\n",
        "query_cache = {}\n",
        "\n",
        "def cached_ai_agent(query, df, use_cache=True):\n",
        "    # Check cache first\n",
        "    # If not in cache, call API and store result\n",
        "    # Return cached or new response\n",
        "    pass\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### Exercise 7: Cost Tracking\n",
        "\n",
        "**Task**: Create a cost tracker that monitors API usage.\n",
        "\n",
        "**Requirements**:\n",
        "- Track number of requests\n",
        "- Track total tokens used\n",
        "- Calculate estimated cost (you'll need to look up current pricing)\n",
        "- Display usage statistics\n",
        "\n",
        "**Template**:\n",
        "```python\n",
        "class CostTracker:\n",
        "    def __init__(self):\n",
        "        self.requests = 0\n",
        "        self.total_tokens = 0\n",
        "        # Add more tracking variables\n",
        "    \n",
        "    def add_usage(self, tokens):\n",
        "        # Update tracking\n",
        "        pass\n",
        "    \n",
        "    def get_stats(self):\n",
        "        # Return usage statistics\n",
        "        pass\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### Exercise 8: Multi-Model Comparison\n",
        "\n",
        "**Task**: Compare responses from different GPT models.\n",
        "\n",
        "**Requirements**:\n",
        "- Test the same query with gpt-3.5-turbo and gpt-4o\n",
        "- Compare response quality\n",
        "- Compare response time\n",
        "- Compare token usage\n",
        "\n",
        "**Template**:\n",
        "```python\n",
        "def compare_models(query, df):\n",
        "    models = [\"gpt-3.5-turbo\", \"gpt-4o\"]\n",
        "    results = {}\n",
        "    for model in models:\n",
        "        # Test with each model\n",
        "        # Store results\n",
        "        pass\n",
        "    return results\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### Exercise 9: Interactive Improvements\n",
        "\n",
        "**Task**: Enhance the interactive loop with more features.\n",
        "\n",
        "**Requirements**:\n",
        "- Add command history (use arrow keys)\n",
        "- Add ability to save conversation\n",
        "- Add ability to export responses\n",
        "- Add query suggestions\n",
        "\n",
        "---\n",
        "\n",
        "### Exercise 10: Real Data Analysis Integration\n",
        "\n",
        "**Task**: Create a version that performs actual data analysis and includes results in the prompt.\n",
        "\n",
        "**Requirements**:\n",
        "- Detect query type (statistical, filtering, aggregation, etc.)\n",
        "- Perform the actual pandas operation\n",
        "- Include results in the prompt\n",
        "- Let AI provide natural language explanation\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "def smart_ai_agent(query, df):\n",
        "    # Analyze query to determine what operation is needed\n",
        "    # Perform the operation\n",
        "    # Include result in prompt\n",
        "    # Get AI explanation\n",
        "    pass\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exercise Solutions (Try First, Then Check!)\n",
        "\n",
        "<details>\n",
        "<summary>Click to view Exercise 2 Solution</summary>\n",
        "\n",
        "```python\n",
        "def ask_question(query, df):\n",
        "    \"\"\"Ask a question and print formatted response.\"\"\"\n",
        "    print(\"=\" * 60)\n",
        "    print(f\"‚ùì Question: {query}\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    try:\n",
        "        response = ai_agent(query, df)\n",
        "        print(f\"ü§ñ Answer:\\n{response}\")\n",
        "        print(\"=\" * 60)\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error: {e}\")\n",
        "        print(\"=\" * 60)\n",
        "\n",
        "# Test\n",
        "ask_question(\"How many rows are in the dataset?\", df)\n",
        "```\n",
        "\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary>Click to view Exercise 3 Solution</summary>\n",
        "\n",
        "```python\n",
        "def batch_questions(questions_list, df):\n",
        "    \"\"\"Process multiple questions at once.\"\"\"\n",
        "    results = {}\n",
        "    \n",
        "    for i, question in enumerate(questions_list, 1):\n",
        "        print(f\"Processing question {i}/{len(questions_list)}: {question}\")\n",
        "        try:\n",
        "            answer = ai_agent(question, df)\n",
        "            results[question] = {\n",
        "                'answer': answer,\n",
        "                'status': 'success'\n",
        "            }\n",
        "        except Exception as e:\n",
        "            results[question] = {\n",
        "                'answer': None,\n",
        "                'status': 'error',\n",
        "                'error': str(e)\n",
        "            }\n",
        "    \n",
        "    return results\n",
        "\n",
        "# Test\n",
        "questions = [\n",
        "    \"What is the average loan amount?\",\n",
        "    \"How many applicants are graduates?\",\n",
        "    \"What percentage of loans were approved?\"\n",
        "]\n",
        "results = batch_questions(questions, df)\n",
        "\n",
        "# Display results\n",
        "for q, r in results.items():\n",
        "    print(f\"\\nQ: {q}\")\n",
        "    print(f\"A: {r['answer']}\")\n",
        "```\n",
        "\n",
        "</details>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Additional Examples and Use Cases\n",
        "\n",
        "### Example 1: Financial Analysis Agent\n",
        "\n",
        "Let's create a specialized agent for financial analysis:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def financial_analysis_agent(query, df):\n",
        "    \"\"\"Specialized agent for financial analysis queries.\"\"\"\n",
        "    # Calculate key financial metrics\n",
        "    total_income = df['ApplicantIncome'].sum()\n",
        "    avg_income = df['ApplicantIncome'].mean()\n",
        "    total_loans = df['LoanAmount'].sum()\n",
        "    avg_loan = df['LoanAmount'].mean()\n",
        "    approval_rate = (df['Loan_Status'] == 'Y').mean() * 100\n",
        "    \n",
        "    financial_context = f\"\"\"\n",
        "Financial Summary:\n",
        "- Total Applicant Income: {total_income:,.2f}\n",
        "- Average Applicant Income: {avg_income:,.2f}\n",
        "- Total Loan Amount: {total_loans:,.2f}\n",
        "- Average Loan Amount: {avg_loan:,.2f}\n",
        "- Loan Approval Rate: {approval_rate:.2f}%\n",
        "\"\"\"\n",
        "    \n",
        "    data_context = create_data_summary(df)\n",
        "    \n",
        "    prompt = f\"\"\"You are a financial analysis expert AI agent.\n",
        "\n",
        "Dataset Summary:\n",
        "{data_context}\n",
        "\n",
        "Financial Metrics:\n",
        "{financial_context}\n",
        "\n",
        "User Question: '{query}'\n",
        "\n",
        "Provide a detailed financial analysis with insights and recommendations.\"\"\"\n",
        "    \n",
        "    try:\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-4o\",\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "            temperature=0.3,\n",
        "            max_tokens=600\n",
        "        )\n",
        "        return response.choices[0].message.content\n",
        "    except Exception as e:\n",
        "        return f\"Error: {str(e)}\"\n",
        "\n",
        "# Test financial analysis agent\n",
        "print(\"Financial Analysis Agent Test\")\n",
        "print(\"=\" * 60)\n",
        "financial_query = \"What insights can you provide about loan approval patterns?\"\n",
        "financial_response = financial_analysis_agent(financial_query, df)\n",
        "print(f\"Query: {financial_query}\\n\")\n",
        "print(f\"Response:\\n{financial_response}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Example 2: Comparison Queries\n",
        "\n",
        "Handle queries that require comparing different groups:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example: Compare different groups\n",
        "comparison_query = \"Compare loan approval rates between urban and rural property areas\"\n",
        "\n",
        "# Calculate actual statistics\n",
        "urban_approved = (df[df['Property_Area'] == 'Urban']['Loan_Status'] == 'Y').mean() * 100\n",
        "rural_approved = (df[df['Property_Area'] == 'Rural']['Loan_Status'] == 'Y').mean() * 100\n",
        "semiurban_approved = (df[df['Property_Area'] == 'Semiurban']['Loan_Status'] == 'Y').mean() * 100\n",
        "\n",
        "comparison_stats = f\"\"\"\n",
        "Approval Rates by Property Area:\n",
        "- Urban: {urban_approved:.2f}%\n",
        "- Rural: {rural_approved:.2f}%\n",
        "- Semiurban: {semiurban_approved:.2f}%\n",
        "\"\"\"\n",
        "\n",
        "data_context = create_data_summary(df)\n",
        "\n",
        "prompt = f\"\"\"You are a data analysis expert.\n",
        "\n",
        "Dataset Summary:\n",
        "{data_context}\n",
        "\n",
        "Actual Statistics:\n",
        "{comparison_stats}\n",
        "\n",
        "User Question: '{comparison_query}'\n",
        "\n",
        "Provide a detailed comparison with insights.\"\"\"\n",
        "\n",
        "try:\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        temperature=0.2,\n",
        "        max_tokens=500\n",
        "    )\n",
        "    print(\"Comparison Analysis:\")\n",
        "    print(\"=\" * 60)\n",
        "    print(response.choices[0].message.content)\n",
        "except Exception as e:\n",
        "    print(f\"Error: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Best Practices\n",
        "\n",
        "### 1. Prompt Engineering\n",
        "\n",
        "- **Be Specific**: Clearly define the agent's role and capabilities\n",
        "- **Provide Context**: Give enough information without overwhelming\n",
        "- **Set Expectations**: Tell the model what format you want\n",
        "- **Use Examples**: Show the model what good responses look like\n",
        "- **Iterate**: Refine prompts based on results\n",
        "\n",
        "### 2. Cost Optimization\n",
        "\n",
        "- **Use Appropriate Models**: Use cheaper models for simple tasks\n",
        "- **Limit Token Usage**: Set reasonable max_tokens\n",
        "- **Cache Responses**: Avoid redundant API calls\n",
        "- **Batch Processing**: Group similar queries when possible\n",
        "- **Monitor Usage**: Track your API usage regularly\n",
        "\n",
        "### 3. Error Handling\n",
        "\n",
        "- **Always Use Try-Except**: Wrap API calls in error handling\n",
        "- **Implement Retries**: Use exponential backoff for transient errors\n",
        "- **Validate Inputs**: Check queries before sending to API\n",
        "- **Provide Fallbacks**: Have backup responses for errors\n",
        "- **Log Errors**: Keep track of what went wrong\n",
        "\n",
        "### 4. Security\n",
        "\n",
        "- **Never Commit API Keys**: Use environment variables\n",
        "- **Use .gitignore**: Exclude .env files from version control\n",
        "- **Rotate Keys**: Change API keys periodically\n",
        "- **Set Usage Limits**: Configure limits in OpenAI dashboard\n",
        "- **Monitor Access**: Check for unauthorized usage\n",
        "\n",
        "### 5. Performance\n",
        "\n",
        "- **Optimize Prompts**: Shorter prompts = faster + cheaper\n",
        "- **Use Streaming**: For long responses, use streaming API\n",
        "- **Parallel Requests**: Process multiple queries concurrently (with rate limit awareness)\n",
        "- **Response Caching**: Cache identical queries\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "### What We've Learned\n",
        "\n",
        "1. **OpenAI API Setup**: How to get and configure your API key\n",
        "2. **Basic AI Agent**: Creating a simple agent that answers questions about data\n",
        "3. **Data Summarization**: Efficiently summarizing datasets for AI consumption\n",
        "4. **Prompt Engineering**: Crafting effective prompts for better responses\n",
        "5. **Error Handling**: Building robust agents that handle edge cases\n",
        "6. **Advanced Features**: Enhanced agents with better capabilities\n",
        "7. **Troubleshooting**: Common issues and their solutions\n",
        "\n",
        "### Key Takeaways\n",
        "\n",
        "- AI agents can understand context and provide natural language responses\n",
        "- Proper prompt engineering is crucial for good results\n",
        "- Error handling and validation are essential for production use\n",
        "- Cost management is important when using paid APIs\n",
        "- Security best practices protect your API keys and data\n",
        "\n",
        "### Next Steps\n",
        "\n",
        "1. **Experiment**: Try different prompts and models\n",
        "2. **Extend**: Add more features like caching, logging, etc.\n",
        "3. **Deploy**: Create a web interface or API for your agent\n",
        "4. **Optimize**: Improve performance and reduce costs\n",
        "5. **Learn More**: Explore other OpenAI features (embeddings, fine-tuning, etc.)\n",
        "\n",
        "### Resources\n",
        "\n",
        "- [OpenAI API Documentation](https://platform.openai.com/docs)\n",
        "- [OpenAI Python SDK](https://github.com/openai/openai-python)\n",
        "- [OpenAI Pricing](https://openai.com/pricing)\n",
        "- [Prompt Engineering Guide](https://platform.openai.com/docs/guides/prompt-engineering)\n",
        "\n",
        "---\n",
        "\n",
        "## Conclusion\n",
        "\n",
        "Congratulations! You've learned how to build an AI agent using the OpenAI API. You now have the knowledge to:\n",
        "- Set up and configure the OpenAI API\n",
        "- Build intelligent agents that understand data\n",
        "- Handle errors and edge cases\n",
        "- Optimize for cost and performance\n",
        "- Troubleshoot common issues\n",
        "\n",
        "Keep experimenting and building! The field of AI agents is rapidly evolving, and there's always more to learn.\n",
        "\n",
        "**Happy Coding! üöÄ**\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "AI Agents",
      "language": "python",
      "name": "ai-agents"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
