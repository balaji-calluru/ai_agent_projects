{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a Multi-Agent System With LangGraph\n",
    "\n",
    "The future of AI isn't about building a smarter chatbot; it's about building a team.\n",
    "\n",
    "Today, we will build that team using LangGraph. We will create a Multi-Agent System where one AI agent acts as a Researcher (browsing the web), and another acts as a Writer (synthesising that info). They will pass work to each other like colleagues in a newsroom.\n",
    "\n",
    "If you are a student or a developer looking to break into the Agentic Workflow space, this is the perfect starting point. Let's dive in.\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will be able to:\n",
    "\n",
    "- Understand the core concepts of LangGraph and multi-agent systems\n",
    "- Build a state-based workflow with multiple AI agents\n",
    "- Integrate external tools (web search) with LLMs\n",
    "- Create a production-ready multi-agent system with error handling\n",
    "- Visualize and debug agent workflows\n",
    "- Extend the system with additional agents or capabilities\n",
    "\n",
    "## Resources and Documentation\n",
    "\n",
    "- **LangGraph Documentation**: https://langchain-ai.github.io/langgraph/\n",
    "- **LangChain Documentation**: https://python.langchain.com/\n",
    "- **Ollama**: https://ollama.com/\n",
    "- **LangGraph GitHub**: https://github.com/langchain-ai/langgraph\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is LangGraph?\n",
    "\n",
    "Before we write code, let's understand what we are building. Imagine a relay race. Runner A has the baton (data). They run their lap (task) and then pass the baton to Runner B. Runner B cannot start until they receive the baton.\n",
    "\n",
    "**LangGraph** allows us to code this relay race. It's a library for building stateful, multi-actor applications with LLMs. Think of it as a way to create workflows where AI agents can collaborate, make decisions, and pass information between each other.\n",
    "\n",
    "### Key Concepts\n",
    "\n",
    "- **Nodes**: These are the agents or functions (The Runners). Each node performs a specific task and can read/write to the shared state.\n",
    "- **Edges**: These are the rules of who goes next (The Track). They define the flow of execution between nodes.\n",
    "- **State**: This is the shared memory (The Baton). It's a TypedDict that all nodes can access and modify.\n",
    "\n",
    "Instead of one giant prompt, we break the logic into small, reliable steps. This approach offers several advantages:\n",
    "\n",
    "1. **Modularity**: Each agent has a single, well-defined responsibility\n",
    "2. **Debugging**: You can inspect the state at each step\n",
    "3. **Scalability**: Easy to add new agents or modify existing ones\n",
    "4. **Reliability**: Errors in one agent don't crash the entire system\n",
    "\n",
    "### When to Use LangGraph\n",
    "\n",
    "LangGraph is ideal for:\n",
    "- Multi-step reasoning tasks\n",
    "- Agentic workflows with decision points\n",
    "- Systems requiring state management\n",
    "- Complex applications that need to coordinate multiple LLM calls\n",
    "\n",
    "**Learn More**: \n",
    "- [LangGraph Introduction](https://langchain-ai.github.io/langgraph/tutorials/introduction/)\n",
    "- [LangGraph Concepts](https://langchain-ai.github.io/langgraph/concepts/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Setup\n",
    "\n",
    "To keep this accessible and free, we are going to use Ollama to run a local LLM (Llama 3). This means you don't need an OpenAI API key to follow along, though you will need a decent internet connection for the search tool.\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "**1. Python Installation**\n",
    "- Make sure you have Python 3.9+ installed\n",
    "- Check your version: `python --version` or `python3 --version`\n",
    "- Download from: https://www.python.org/downloads/\n",
    "\n",
    "**2. Ollama Installation**\n",
    "- Download Ollama from: https://ollama.com/\n",
    "- Install it on your system\n",
    "- Verify installation: `ollama --version`\n",
    "\n",
    "**3. Pull the Llama 3 Model**\n",
    "- Open your terminal and run: `ollama pull llama3`\n",
    "- This will download the model (approximately 4.7GB)\n",
    "- Verify: `ollama list` should show `llama3`\n",
    "\n",
    "**4. Install Python Dependencies**\n",
    "\n",
    "Create a virtual environment (highly recommended):\n",
    "```bash\n",
    "python -m venv venv\n",
    "source venv/bin/activate  # On Windows: venv\\Scripts\\activate\n",
    "```\n",
    "\n",
    "Install required packages:\n",
    "```bash\n",
    "pip install langgraph langchain langchain-community langchain-core langchain-ollama duckduckgo-search\n",
    "```\n",
    "\n",
    "### Alternative: Using OpenAI or Other LLMs\n",
    "\n",
    "If you prefer to use OpenAI or other cloud-based LLMs, you can replace `ChatOllama` with:\n",
    "- `ChatOpenAI` from `langchain_openai` (requires API key)\n",
    "- `ChatAnthropic` from `langchain_anthropic` (requires API key)\n",
    "- Other providers supported by LangChain\n",
    "\n",
    "**Note**: The rest of the code will work the same way, just change the LLM initialization.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Multi-Agent System With LangGraph: Getting Started\n",
    "\n",
    "We will build this in three parts: **The State**, **The Agents**, and **The Graph**.\n",
    "\n",
    "### Architecture Overview\n",
    "\n",
    "Our system will follow this flow:\n",
    "\n",
    "```\n",
    "[Start] ‚Üí [Researcher Agent] ‚Üí [Writer Agent] ‚Üí [End]\n",
    "           (Web Search)         (LLM Generation)\n",
    "```\n",
    "\n",
    "1. **The State**: Define what data flows between agents\n",
    "2. **The Agents**: Create the Researcher and Writer nodes\n",
    "3. **The Graph**: Wire everything together and define the execution flow\n",
    "\n",
    "Let's start building!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Defining the Shared State\n",
    "\n",
    "Think of the AgentState as a shared clipboard that hangs on the office wall. Every agent can read from it and write to it. This ensures that when the Researcher finds something, the Writer can actually see it.\n",
    "\n",
    "**Why TypedDict?**\n",
    "- **Type Safety**: Python's type checker can validate your code\n",
    "- **Documentation**: Clear contract of what data is available\n",
    "- **IDE Support**: Better autocomplete and error detection\n",
    "- **Runtime Validation**: LangGraph uses this to ensure state consistency\n",
    "\n",
    "**Key Points:**\n",
    "- Each field in the state can be read by any node\n",
    "- Nodes return dictionaries with only the fields they want to update\n",
    "- LangGraph automatically merges updates into the state\n",
    "- The state persists throughout the entire workflow execution\n",
    "\n",
    "Without a structured state, agents are just shouting into the void. This TypedDict ensures type safety and clarity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "from typing import TypedDict, List\n",
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "# ----- Shared State -----\n",
    "class AgentState(TypedDict):\n",
    "    \"\"\"\n",
    "    The shared state that flows through our multi-agent system.\n",
    "    \n",
    "    Fields:\n",
    "        topic: The research topic provided by the user\n",
    "        research_data: List of research findings from the Researcher agent\n",
    "        blog_post: The final blog post generated by the Writer agent\n",
    "    \"\"\"\n",
    "    topic: str\n",
    "    research_data: List[str]  # A list of findings from web search\n",
    "    blog_post: str            # The final output generated by the Writer\n",
    "\n",
    "# Note: TypedDict is a special dictionary type that provides type hints\n",
    "# while still being a regular dict at runtime. This is perfect for LangGraph!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: The Researcher Agent\n",
    "\n",
    "Our first employee is the Researcher. Their job is simple: take a topic, search DuckDuckGo, and paste the results onto the clipboard (State).\n",
    "\n",
    "**Design Decision: Why No LLM Here?**\n",
    "\n",
    "Notice we aren't using an LLM here yet! We are just using a deterministic tool (Search). This approach offers several benefits:\n",
    "\n",
    "1. **Cost Efficiency**: Web search is free, LLM calls cost money/tokens\n",
    "2. **Speed**: Search is faster than generating text\n",
    "3. **Accuracy**: Grounding in real data reduces hallucinations\n",
    "4. **Reliability**: Deterministic tools are more predictable\n",
    "\n",
    "**The Researcher's Responsibilities:**\n",
    "- Extract the topic from the state\n",
    "- Perform web search using DuckDuckGo\n",
    "- Handle errors gracefully\n",
    "- Append results to the research_data list\n",
    "\n",
    "**DuckDuckGo Search**: \n",
    "- Privacy-focused search engine\n",
    "- No API key required\n",
    "- Good for general web searches\n",
    "- Documentation: https://github.com/deedy5/duckduckgo_search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import DuckDuckGo search tool\n",
    "# Note: If this import fails, try: from duckduckgo_search import DDGS\n",
    "# and use: search = DDGS().text(query, max_results=5)\n",
    "from langchain_community.tools.ddg_search import DuckDuckGoSearchRun\n",
    "import logging\n",
    "\n",
    "# Set up logging for better debugging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def researcher_node(state: AgentState) -> dict:\n",
    "    \"\"\"\n",
    "    Researcher agent that searches DuckDuckGo for the latest news and key facts about a given topic.\n",
    "    \n",
    "    Args:\n",
    "        state: The current AgentState containing the topic and existing research_data\n",
    "        \n",
    "    Returns:\n",
    "        dict: Updated state with new research findings appended to research_data\n",
    "        \n",
    "    Note:\n",
    "        This function only returns the fields it wants to update. LangGraph will\n",
    "        automatically merge this with the existing state.\n",
    "    \"\"\"\n",
    "    # Extract topic from state\n",
    "    topic = state.get(\"topic\", \"\")\n",
    "    \n",
    "    if not topic:\n",
    "        logger.warning(\"No topic provided in state\")\n",
    "        return {\"research_data\": state.get(\"research_data\", []) + [\"Error: No topic provided\"]}\n",
    "    \n",
    "    logger.info(f\"üîç Researcher is looking up: {topic}...\")\n",
    "    print(f\"Researcher is looking up: {topic}...\")\n",
    "    \n",
    "    # Initialize the search tool\n",
    "    search = DuckDuckGoSearchRun()\n",
    "    \n",
    "    # Perform the search with error handling\n",
    "    try:\n",
    "        # Construct the search query\n",
    "        # You can customize this query format based on your needs\n",
    "        query = f\"key facts and latest news about {topic}\"\n",
    "        logger.info(f\"Search query: {query}\")\n",
    "        \n",
    "        # Execute the search\n",
    "        results = search.run(query)\n",
    "        \n",
    "        # Validate results\n",
    "        if not results or len(str(results).strip()) == 0:\n",
    "            results = f\"No results found for topic: {topic}\"\n",
    "            logger.warning(\"Search returned empty results\")\n",
    "        else:\n",
    "            logger.info(f\"Search completed successfully. Results length: {len(str(results))} characters\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        # Graceful error handling\n",
    "        error_msg = f\"Search error for topic '{topic}': {str(e)}\"\n",
    "        logger.error(error_msg)\n",
    "        results = error_msg\n",
    "        \n",
    "    print(\"‚úÖ Research complete.\")\n",
    "    logger.info(\"Research phase completed\")\n",
    "    \n",
    "    # Get existing research data or initialize empty list\n",
    "    existing_research = state.get(\"research_data\", [])\n",
    "    \n",
    "    # Return only the fields we want to update\n",
    "    # LangGraph will merge this with the existing state\n",
    "    return {\n",
    "        \"research_data\": existing_research + [results]\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: The Writer Agent\n",
    "\n",
    "Now, the Writer steps in. This agent uses Llama 3 (via Ollama). It reads the research_data found by the previous agent and drafts the content.\n",
    "\n",
    "**The Writer's Responsibilities:**\n",
    "- Read the research findings from the state\n",
    "- Use an LLM to synthesize the information into a blog post\n",
    "- Follow the prompt template to ensure quality output\n",
    "- Return the generated blog post\n",
    "\n",
    "**Understanding Temperature:**\n",
    "- **Temperature = 0.7**: Balanced creativity and consistency (good for blog posts)\n",
    "- **Temperature = 0.1**: More deterministic, factual (good for reports)\n",
    "- **Temperature = 1.0+**: More creative, less consistent (good for creative writing)\n",
    "\n",
    "**Prompt Engineering Tips:**\n",
    "- Be specific about the desired output format\n",
    "- Include constraints (e.g., \"based ONLY on the following research data\")\n",
    "- Set the role/context clearly (\"You are a tech blog writer\")\n",
    "- Specify length if needed (\"short, engaging blog post\")\n",
    "\n",
    "**LangChain Prompt Templates**: \n",
    "- Documentation: https://python.langchain.com/docs/modules/model_io/prompts/\n",
    "- Allows for reusable, parameterized prompts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def writer_node(state: AgentState) -> dict:\n",
    "    \"\"\"\n",
    "    Writer agent that synthesizes research data into a blog post using an LLM.\n",
    "    \n",
    "    Args:\n",
    "        state: The current AgentState containing topic and research_data\n",
    "        \n",
    "    Returns:\n",
    "        dict: Updated state with the generated blog_post\n",
    "        \n",
    "    Note:\n",
    "        This uses ChatOllama to run a local LLM. Make sure Ollama is running\n",
    "        and the llama3 model is installed.\n",
    "    \"\"\"\n",
    "    logger.info(\"‚úçÔ∏è Writer is drafting the post...\")\n",
    "    print(\"Writer is drafting the post...\")\n",
    "    \n",
    "    # Extract data from state\n",
    "    topic = state.get(\"topic\", \"Unknown Topic\")\n",
    "    research_data = state.get(\"research_data\", [])\n",
    "    \n",
    "    # Get the most recent research findings\n",
    "    # We use [-1] to get the last item, or empty string if list is empty\n",
    "    data = research_data[-1] if research_data else \"\"\n",
    "    \n",
    "    # Validate that we have research data\n",
    "    if not data or len(data.strip()) == 0:\n",
    "        logger.warning(\"No research data available for writing\")\n",
    "        return {\n",
    "            \"blog_post\": f\"Error: No research data found for topic '{topic}'. Please ensure the Researcher agent completed successfully.\"\n",
    "        }\n",
    "    \n",
    "    logger.info(f\"Using research data of length: {len(data)} characters\")\n",
    "    \n",
    "    # Initialize the LLM\n",
    "    # Note: Make sure Ollama is running and llama3 model is pulled\n",
    "    try:\n",
    "        llm = ChatOllama(\n",
    "            model=\"llama3\",  # You can change this to other models like \"llama3.1\", \"mistral\", etc.\n",
    "            temperature=0.7,  # Controls creativity: 0.0 (deterministic) to 1.0+ (creative)\n",
    "        )\n",
    "        logger.info(\"LLM initialized successfully\")\n",
    "    except Exception as e:\n",
    "        error_msg = f\"Failed to initialize LLM: {str(e)}. Make sure Ollama is running and the model is installed.\"\n",
    "        logger.error(error_msg)\n",
    "        return {\"blog_post\": error_msg}\n",
    "    \n",
    "    # Create the prompt template\n",
    "    # This template defines the role, task, and constraints for the LLM\n",
    "    prompt = ChatPromptTemplate.from_template(\n",
    "        \"\"\"You are a tech blog writer with expertise in AI and technology trends.\n",
    "\n",
    "Your task: Write a short, engaging blog post about \"{topic}\" \n",
    "based ONLY on the following research data. Do not make up information.\n",
    "\n",
    "Research Data:\n",
    "{data}\n",
    "\n",
    "Instructions:\n",
    "- Write in a clear, engaging style\n",
    "- Use the research data as your source of truth\n",
    "- Keep it concise (2-3 paragraphs)\n",
    "- Make it interesting for a tech-savvy audience\n",
    "- Do not add information not present in the research data\n",
    "\n",
    "Return just the blog post content, no additional commentary.\"\"\"\n",
    "    )\n",
    "    \n",
    "    # Create a chain: prompt -> LLM\n",
    "    # The pipe operator (|) chains components together\n",
    "    chain = prompt | llm\n",
    "    \n",
    "    # Invoke the chain with our data\n",
    "    try:\n",
    "        logger.info(\"Invoking LLM to generate blog post...\")\n",
    "        response = chain.invoke({\n",
    "            \"topic\": topic,\n",
    "            \"data\": data\n",
    "        })\n",
    "        \n",
    "        # Extract the content from the response\n",
    "        blog_post = response.content if hasattr(response, 'content') else str(response)\n",
    "        \n",
    "        logger.info(f\"Blog post generated successfully. Length: {len(blog_post)} characters\")\n",
    "        print(\"‚úÖ Writing complete.\")\n",
    "        \n",
    "        return {\"blog_post\": blog_post}\n",
    "        \n",
    "    except Exception as e:\n",
    "        error_msg = f\"Error generating blog post: {str(e)}\"\n",
    "        logger.error(error_msg)\n",
    "        return {\"blog_post\": error_msg}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Wiring the Graph\n",
    "\n",
    "This is the key part. We define the workflow. It is a linear path: Start ‚Üí Researcher ‚Üí Writer ‚Üí End.\n",
    "\n",
    "**Understanding the Graph Structure:**\n",
    "\n",
    "1. **StateGraph**: The main class that manages the workflow\n",
    "2. **add_node()**: Registers an agent/function as a node\n",
    "3. **set_entry_point()**: Defines where the workflow starts\n",
    "4. **add_edge()**: Connects nodes in sequence\n",
    "5. **compile()**: Finalizes the graph and makes it executable\n",
    "\n",
    "**Graph Flow Visualization:**\n",
    "```\n",
    "[START]\n",
    "   ‚Üì\n",
    "[Researcher Node] ‚Üí Searches web, updates research_data\n",
    "   ‚Üì\n",
    "[Writer Node] ‚Üí Generates blog post, updates blog_post\n",
    "   ‚Üì\n",
    "[END]\n",
    "```\n",
    "\n",
    "**Why This Structure?**\n",
    "- **Linear Flow**: Simple and predictable\n",
    "- **Sequential Dependencies**: Writer needs research data first\n",
    "- **Easy to Extend**: Can add more nodes (e.g., Editor, Fact-Checker)\n",
    "\n",
    "**Learn More**: \n",
    "- [LangGraph Graph Construction](https://langchain-ai.github.io/langgraph/how-tos/graph-construction/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Graph compiled successfully!\n",
      "\n",
      "Graph Structure:\n",
      "  START ‚Üí Researcher ‚Üí Writer ‚Üí END\n"
     ]
    }
   ],
   "source": [
    "# ----- Build the LangGraph -----\n",
    "\n",
    "# Initialize the StateGraph with our AgentState\n",
    "# This tells LangGraph what the structure of our state should be\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "# Add nodes (agents) to the graph\n",
    "# Each node is a function that receives state and returns updates\n",
    "workflow.add_node(\"Researcher\", researcher_node)\n",
    "workflow.add_node(\"Writer\", writer_node)\n",
    "\n",
    "# Define the execution flow\n",
    "# Flow: Start ‚Üí Researcher ‚Üí Writer ‚Üí END\n",
    "\n",
    "# Set the entry point (where execution begins)\n",
    "workflow.set_entry_point(\"Researcher\")\n",
    "\n",
    "# Add edges (connections between nodes)\n",
    "# This defines the order of execution\n",
    "workflow.add_edge(\"Researcher\", \"Writer\")  # After Researcher, go to Writer\n",
    "workflow.add_edge(\"Writer\", END)           # After Writer, end the workflow\n",
    "\n",
    "# Compile the graph to make it executable\n",
    "# This validates the graph structure and creates the runnable app\n",
    "app = workflow.compile()\n",
    "\n",
    "print(\"‚úÖ Graph compiled successfully!\")\n",
    "print(\"\\nGraph Structure:\")\n",
    "print(\"  START ‚Üí Researcher ‚Üí Writer ‚Üí END\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Running the System\n",
    "\n",
    "Now, let's fire it up! We trigger the `app.invoke()` method with our initial input.\n",
    "\n",
    "**What Happens When You Run:**\n",
    "\n",
    "1. **Initialization**: The graph receives the initial state with the topic\n",
    "2. **Researcher Phase**: \n",
    "   - Prints \"Researcher is looking up: [topic]...\"\n",
    "   - Searches DuckDuckGo (may take 5-10 seconds)\n",
    "   - Updates state with research findings\n",
    "3. **Writer Phase**:\n",
    "   - Prints \"Writer is drafting the post...\"\n",
    "   - Sends research data to LLM (may take 10-30 seconds depending on model)\n",
    "   - Generates blog post based on research\n",
    "4. **Completion**: Returns final state with blog_post field populated\n",
    "\n",
    "**Understanding app.invoke():**\n",
    "- Takes the initial state as input\n",
    "- Executes all nodes in sequence according to the graph\n",
    "- Returns the final state after all nodes complete\n",
    "- Blocks until the entire workflow finishes\n",
    "\n",
    "**Alternative: Streaming Execution**\n",
    "- Use `app.stream()` for real-time updates\n",
    "- See intermediate states as they're generated\n",
    "- Useful for long-running workflows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:üîç Researcher is looking up: The future of AI Agents...\n",
      "INFO:__main__:Search query: key facts and latest news about The future of AI Agents\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting the Multi-Agent System...\n",
      "\n",
      "Executing workflow...\n",
      "============================================================\n",
      "Researcher is looking up: The future of AI Agents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:ddgs.ddgs:Error in engine grokipedia: DDGSException(\"RuntimeError: RuntimeError('error sending request for url (https://wt.wikipedia.org/w/api.php?action=opensearch&profile=fuzzy&limit=1&search=key%20facts%20and%20latest%20news%20about%20The%20future%20of%20AI%20Agents): client error (Connect)\\\\n\\\\nCaused by:\\\\n    0: client error (Connect)\\\\n    1: dns error: failed to lookup address information: nodename nor servname provided, or not known\\\\n    2: failed to lookup address information: nodename nor servname provided, or not known')\")\n",
      "INFO:primp:response: https://grokipedia.com/api/typeahead?query=key+facts+and+latest+news+about+The+future+of+AI+Agents&limit=1 200\n",
      "INFO:primp:response: https://www.mojeek.com/search?q=key+facts+and+latest+news+about+The+future+of+AI+Agents 200\n",
      "INFO:__main__:Search completed successfully. Results length: 689 characters\n",
      "INFO:__main__:Research phase completed\n",
      "INFO:__main__:‚úçÔ∏è Writer is drafting the post...\n",
      "INFO:__main__:Using research data of length: 689 characters\n",
      "INFO:__main__:LLM initialized successfully\n",
      "INFO:__main__:Invoking LLM to generate blog post...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Research complete.\n",
      "Writer is drafting the post...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Blog post generated successfully. Length: 1334 characters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Writing complete.\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "FINAL OUTPUT\n",
      "============================================================\n",
      "\n",
      "üìù Generated Blog Post:\n",
      "\n",
      "The Future of AI Agents: Revolutionizing Automation\n",
      "\n",
      "As AI agents become increasingly prevalent in various industries, one question remains: what's next? According to Kirby and Marc Escobosa, VP of Salesforce Futures, the future is bright for agentic AI, particularly as it pertains to small and medium-sized businesses. With the rise of AI-powered automation, these organizations will soon rely on AI agents ‚Äì whether in the form of chatbots, virtual assistants, or autonomous execution ‚Äì to streamline operations and stay competitive.\n",
      "\n",
      "The fundamentals of AI agents are simple: they're intelligent systems that can perform tasks independently, often mimicking human behavior. This agentic approach is poised to transform businesses as we know it, enabling seamless communication between humans and machines. With the ability to handle complex tasks, make decisions, and learn from data, AI agents will revolutionize the way companies operate.\n",
      "\n",
      "While some may wonder about the feasibility of implementing agentic AI for small and medium-sized businesses, Escobosa's predictions suggest that even these organizations can benefit from this technology in the not-so-distant future. As the landscape continues to evolve, one thing is clear: AI agents are here to stay, and their impact will be felt across industries and economies alike.\n",
      "\n",
      "============================================================\n",
      "FULL STATE (for debugging)\n",
      "============================================================\n",
      "\n",
      "Topic: The future of AI Agents\n",
      "\n",
      "Research Data Entries: 1\n",
      "Last Research Entry (first 200 chars): Soon, every brand, business, and individual will rely on AI agents ‚Äîwhether in the form of a chatbot , virtual assistant , or autonomous execution ... In this guide, we‚Äôre diving into the fundamentals...\n",
      "\n",
      "Blog Post Length: 1334 characters\n"
     ]
    }
   ],
   "source": [
    "# Prepare the initial state\n",
    "# This is what we pass to the graph to start execution\n",
    "print(\"üöÄ Starting the Multi-Agent System...\\n\")\n",
    "\n",
    "inputs: AgentState = {\n",
    "    \"topic\": \"The future of AI Agents\",\n",
    "    \"research_data\": [],  # Empty initially, will be populated by Researcher\n",
    "    \"blog_post\": \"\",      # Empty initially, will be populated by Writer\n",
    "}\n",
    "\n",
    "# Execute the workflow\n",
    "# This will run all nodes in sequence: Researcher ‚Üí Writer\n",
    "print(\"Executing workflow...\")\n",
    "print(\"=\" * 60)\n",
    "result = app.invoke(inputs)\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Display the results\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"FINAL OUTPUT\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nüìù Generated Blog Post:\\n\")\n",
    "print(result[\"blog_post\"])\n",
    "\n",
    "# Optional: Display the full state for inspection\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"FULL STATE (for debugging)\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nTopic: {result['topic']}\")\n",
    "print(f\"\\nResearch Data Entries: {len(result['research_data'])}\")\n",
    "if result['research_data']:\n",
    "    print(f\"Last Research Entry (first 200 chars): {result['research_data'][-1][:200]}...\")\n",
    "print(f\"\\nBlog Post Length: {len(result['blog_post'])} characters\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Topics and Extensions\n",
    "\n",
    "### Try Different Topics\n",
    "\n",
    "Experiment with different topics to see how the system adapts:\n",
    "\n",
    "```python\n",
    "# Try these topics:\n",
    "topics = [\n",
    "    \"Quantum computing breakthroughs 2024\",\n",
    "    \"Sustainable energy solutions\",\n",
    "    \"The impact of AI on healthcare\",\n",
    "    \"Space exploration recent discoveries\"\n",
    "]\n",
    "\n",
    "for topic in topics:\n",
    "    result = app.invoke({\n",
    "        \"topic\": topic,\n",
    "        \"research_data\": [],\n",
    "        \"blog_post\": \"\"\n",
    "    })\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Topic: {topic}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(result[\"blog_post\"][:500] + \"...\\n\")\n",
    "```\n",
    "\n",
    "### Visualize the Graph\n",
    "\n",
    "You can visualize your graph structure:\n",
    "\n",
    "```python\n",
    "try:\n",
    "    from IPython.display import Image, display\n",
    "    # Generate graph visualization\n",
    "    display(Image(app.get_graph().draw_mermaid_png()))\n",
    "except:\n",
    "    print(\"Graph visualization requires additional dependencies\")\n",
    "    print(\"Install with: pip install pygraphviz\")\n",
    "```\n",
    "\n",
    "### Add More Agents\n",
    "\n",
    "Consider extending the system with:\n",
    "\n",
    "1. **Editor Agent**: Reviews and improves the blog post\n",
    "2. **Fact-Checker Agent**: Validates claims against research\n",
    "3. **SEO Agent**: Optimizes content for search engines\n",
    "4. **Summarizer Agent**: Creates a summary version\n",
    "\n",
    "### Error Handling and Monitoring\n",
    "\n",
    "For production systems, consider:\n",
    "- Adding retry logic for failed operations\n",
    "- Implementing state persistence\n",
    "- Adding monitoring and logging\n",
    "- Creating fallback mechanisms\n",
    "\n",
    "### Conditional Routing\n",
    "\n",
    "LangGraph supports conditional edges for decision-making:\n",
    "\n",
    "```python\n",
    "def should_continue(state):\n",
    "    if len(state[\"research_data\"]) > 0:\n",
    "        return \"Writer\"\n",
    "    else:\n",
    "        return \"Researcher\"  # Retry research\n",
    "\n",
    "workflow.add_conditional_edges(\"Researcher\", should_continue)\n",
    "```\n",
    "\n",
    "## Closing Thoughts\n",
    "\n",
    "So, this is how to build a Multi-Agent System with LangGraph. Building Multi-Agent systems can feel intimidating. It requires us to stop thinking like users, prompting a box, and start thinking like managers directing a team. \n",
    "\n",
    "**Key Takeaways:**\n",
    "\n",
    "1. **Modularity**: Break complex tasks into specialized agents\n",
    "2. **State Management**: Use TypedDict for clear data contracts\n",
    "3. **Error Handling**: Always plan for failures\n",
    "4. **Extensibility**: Design for easy addition of new agents\n",
    "5. **Testing**: Test each agent independently before integration\n",
    "\n",
    "Now, you are no longer limited by what one neural network can hold in its context window. You are orchestrating a system that can browse, think, critique, and refine.\n",
    "\n",
    "**Next Steps:**\n",
    "- Experiment with different agent configurations\n",
    "- Add more sophisticated routing logic\n",
    "- Integrate with databases or APIs\n",
    "- Deploy your system as a service\n",
    "- Explore LangGraph's advanced features like human-in-the-loop\n",
    "\n",
    "**Resources:**\n",
    "- [LangGraph Tutorials](https://langchain-ai.github.io/langgraph/tutorials/)\n",
    "- [LangGraph Examples](https://github.com/langchain-ai/langgraph/tree/main/examples)\n",
    "- [Multi-Agent Systems Best Practices](https://langchain-ai.github.io/langgraph/how-tos/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIEAAAFNCAIAAACon5t8AAAQAElEQVR4nOydB3wUVR7H38z2zaYX0kghAUJoCWmUI3TwpB8cIM2jCCJgAeSDBWmCihQPUAHR4xAVEJCuiBRRygkEQhMhhZJGS9tNdrNt7r87ybIJu4HszmQyy/vKJ868eVP2/ea9939l/k9IURTCcIoQYbgGa8A9WAPuwRpwD9aAe7AG3MO6BvdyNFdPFT/I0+q0lNGA9DqKJAmj0WQQEwjB/yy7NASJKKP5yYQCvd5gHUKQBGWkSAEB5jRVdUplIEEYKYogCIupDWeZdg2mfcsVAIH5dOs7CoWEXl/NQBeLSVJIydyEjcLFib19BAIBYhOCpfbB7Ruq49vvF983QDILhEgsI6VySC1Cr6uWIohORBMmSZB1igsRpa8eYt4wa0BZrlB5lETIWKVqVThBIL2Bgv9XC4f0pAjKSgNShIy6ag8vkhIGvUFXQWnURoMOdlGjMNmgKSGIHZjXoPCeese/cyvKkbsv2bK9e2JPf8Rzjn5/N/OiSqOiAsLEw94IQ0zDsAbbV90qyNYFNpEMnd4YuRbF99R7NhSoCg3tn/du190XMQeTGmx4JxNy+oSFUch1uZ5WenjLvYAwyZBpjL1kjGnw5XtZ/qHiAZNC0TPAhncyYjt6dezrh5iAGQ3WzckMipQMmPxMCEDzxbsZnv6iYa+FI6chkdN8NS8rKOLZEgB46f3o0vuGnzfnI6dxVoP9X+VSRmLAy8+WADQT329yI61MVVyBnMNZDbIvqUe9zby5xhciWsm/W5qDnMMpDb5efNPLXyiVsduMbMj0HR8M7f9zhwuREzilQckD/aCpbLUe+UJYjOz80WLkBI5rsG9DnliGFJ4i9GzTb2JIRbmxrEiDHMVxDfKyyoOj5Kh+mTNnzu7du1Hd6dWrV25uLmIHsZw89oPjxZHjGug0KC7VE9UvV69eRXUnPz+/qKgIsYZfkOj+HcetIwfbaPnZ6p1rcqcuj0bscOLEiU2bNl25csXPz69t27bTp0+HjcTERPqoQqE4duyYSqXavHnzqVOnMjMz4WiXLl2mTJkilUohwuzZs6HDOSgoCC4yefLkdevW0SdCnOXLlyOmOXXg/qXjJZM+dDA1HMwHdzLKSdasoWvXrr322mtJSUnbt2+H1Lx+/fr8+fORWRj4O3fuXBAANrZs2bJx48YxY8Z88sknEP/QoUPr16+nryASiTLMrFixYujQoRABAqEQY0MAIDRKqtcjh3FwDKes0CAQEogdLly4AK/z+PHjSZIMDAyMjY2F1Hw82ujRo3v06BEZGUnvpqennzx58tVXX4VtGL3Jy8v7+uuv6WzBNn5Bcmd6fBwdRyMQWwogFBcXp9FoXn/99ZSUlNTU1MaNG1tKIWvgZYeCaN68eZBR9Ob30MfHx3IUtKkfAcyP8miMyAEcLItk7tUGIJklJiZm1apV/v7+q1evHjx48CuvvALv+OPR4CgUPhBh165dZ8+eHTdunPVRiUSC6ovCPI0zr6SDGgSGS/U6xB4dO3aEcn/v3r1QE5SUlECe0FcvccGU2LFjx/Dhw0EDKK8gRKlUIo7IzVY7Uzs6qEFErDuM4hYWaBELnDt3Dkp22ICs0K9fv5kzZ0L6gn1pHUen06nV6oCAAHpXq9UeP34ccUTeDbVY4nhGcLx9IBQTZw49RCwAJQ+YQzt37gSj/vLly2D/gBhgaELxAol++vRpKHmguo6IiNizZ09OTk5xcfHChQuhFiktLS0rK3v8ghAT/oLhBFdDLHDvToVXgOP9BY5r4B8izrmuRiwABg+UMMuWLYPG7aRJk9zc3KDcFwpN5gMYS2fOnIGcAZlgyZIlUOuC6Tlo0KDk5ORp06bBbs+ePcEiqnHB0NDQ/v37r127FqoQxAJaNerU3/GpC46Po5WV6v8z7+a0lWw10/jC4S13b5xXvfyR46PojucDNw+h1I3YtuI2era5dkYZ3VaBnMCpeXYDpwRtW5FXS4SuXbvaDDcYDFCgQ0vK5lGwNb28vBALQOsPTCybh6BWhwaHzUeKjo7esGGDzbN+3VEAtknPkY2QEzg7pr915W2dxjj6rQibRx2zF93d3RFr2HukiooKe00KeF2gTrJ5aM2MjB4j/FskO9V3ycC8ivVvZ7ZIce88MAA9Y2xckC1zFwyf4exQLgPzKiYtibr0W2nWpRL0LPHdxzfh7XVeAMTgHK9PZ2Z0GugVl8rMtKcGzuYPbsoUgiEMzedkcq7jp7My/EOEw96IQC7NV/OyBAL04ntNEEMwPOf3q/cytRoU390r5TkmZ8U2EHavzYVmaVisrP9EJmcyMD/3/cS+++nHSsDIaxwj6zMqQCTl/ac+N68p/zhQdD9HK1WQw2aEuHsx3CPL1jcgx76/eyNdVVFGQYciNOXcfURSuVAiE1h/8QK2OH1z2ih//EHgOEGQFKr5jAR9rGag5TuSRyEITjd9n/MoMkkgS6c7HS4gkcFY7VJQ1Gg1Bo3KoCzRa8qMcBl3L2HHAb5RbVgxmtnSwMLxH+7nZZaplQadliIQWe2rI6vPY6ptW8WokqfaMbMGlU8OwxgQxxTP1hXoVK7xjdSjb3jM4TW+C0Km7khSIKCEEtLDVxgRK49L9UFswroGbAM9rH369IFBTcRbeF9Yw9gO3aXKX7AG3IM14B7eawCDmtDfifgMzgfcgzXgHqwB9+D6gHtwPuAerAH3YA24B2vAPbhO5h6cD7gHa8A9vNfAYDBgDbgEMgHbDv/qAd5rwPdMgLAGDQGsAfdgDbiH3z/ABRpoCOeDhgC/fwBFUUFBQYjn8FsDaByw55Wo3uB5C1Mo1DvjMaVhgDXgHqwB92ANuAdrwD1YA+5h4NtYDgHb1Gg08v0TCn5rgFwiK2ANuIf/nS1YA87BGnAP1oB7sAbcgzXgHqwB97iABnz9Tj8+Pp72o2DxgwB/u3XrtmLFCsQ3+NpGS0pKQmZPc6ABaSYgIKCGy2u+wFcNxowZ4+dXzWdYq1atWrdujXgIXzXo3LlzbGysZdfDw2PEiBGIn/C4vwiygq9vpbew5s2b06UTH+GxBgkJCS1btoQNNze3kSNHIt7yZLvo9vWyG2nKikfLf9HL1pu2SNLkoanqAo/CzZ6bKPP/KncrY9jy2gXVas3lLChECpHRYB1CESRhfRbtG0pZWnIu7bzcTZ6clEyHIsqGV7DHXXxVhld6mLK6bPVt68euEYGoupPNo4CQNIrdyK5DAtGTeIIGX76XUVGORBJSV1EZjTQnbJUGhEkCY1U4UbXwvTktqCrHWmC7UBARVa5iT5DIsg0ICMLwmJsuUkgYqntdM6/+YqWW6c6E2QUXhWq4UCOrx6yK/LijL9CVMhrNf61DrH4p/TZRNU6hRTBfkajmA8z6fRKK4K5Ggw75Botrd4Namwbr5mT4hQh7j41AGEcxGAzblmeHRMn6jrfrCtKuBl+8kxHaVPq3wc/ioryMs/2TLA8f4ZDptnOD7Tr51L57UBxjAZii8z8CCm7ZXbfGtga3b2ik7rzvSmo4NApTCEj05xnbLsFtJ7Su3IiMCMMgUPeXPrS9lJZtDQxGqO7ZW4TuWYQyms04W+ACh3tsa2ASjN/zphoidpaesaMBtDt4PnetIWIvSXFZxD1YA+6xrQEpIHBZxDj2DE3bGhgNJp/0CMMo9t5qO3YRgQVgA9uparvVQPF9Sn8DxXai4jq5/qhb+wCXRWxQx/YBQaE6rhD/7nszT5z41bJLkmRQUEjbNu1emTLD3mKT3LJv/w/LVyw+dPA05x4v7LeTUZ0JCQ6dOfNderu8rOzM2VPHfv3lTs6tf6/8AmesWmDyFZDKZPFxiZbdTp26xMUlLlg45+rVSy1btkHPOPZfQnazYZPIaPibl59La3DlysX/blp/7doVTy/vDu07vzh2El1MgRW2Y+d3Bw/ug0wTHhaZmNh+/LgptLNAe6eoVKrvt2/+48ypmzczfX38OnbsAqdIpVI4NG/+bDi3UaOgLVs3LZi/NLVz99u3by5fufjixfPBQSGdO3eHmGKxmH7Chw8fLFr8NtwlNDRsxPCxfZ8fRIfbu++OnVu+/e4/b7z+Ftxl0KBh06fOetq0sF+w2JlfxFDRkZt7B/76+ZnWms/JvTNr9iuaCs2a1f9ZtGBZVtaNN2ZMoqdM79y5ZfM3Xw0dMnLLt/v69x+y/8AuSL4nnPIDpMXG4cPGLFn8yeTJrx379RAkGX1TkUiUlZ0B/xYvWtGmdXxBQf606eNat4pbvuzz4cPHHj7y06rVS+mYUBOsWrN0zOiJK5avjYlp+cm/P7x7t6D2+4J45eVle/Zsf2vOwsEDhyEmsNNXYZ6o4iTnL5xdveZjePXg98PuL7/8KBKK4Cd5eprWCJ81c+4Lo/r/fuJY1y490y+mNW8e26dPPwjv13dwfHySury89lOG/XN0l9Qe4eGR9L0uX07/48zJyZNeRWajrqAgb+1nX9PZYs2nyyVS6bh/vQyZo118EiTiX39dpc+CZB3Qf2hKckfYDggIhNv9ee1yo0aBtdwXLq7RaEaMeBEuhRjCTl+F0ZG+iszMG916PKoPwDTq1LHLxAlTacPjypV0eNfoXwUEBgYFB4devHQeflirVm3Xf7F66ccL27SJ79AhFep2Ok4tp8DLDnX+hx/Ny8i8Tr+h3t6PVvODAo0WAIC3uGnTGIsb1Of69Id/lphgudEbXp7e8LdCo6n9vnRITPOWqI5AyULWqX3gGNZ20d69O9LOn5k1a66HuwcdolIpr/111VokoKjwIfyFUkgudztx8tePli4Awbp27TX5pVehBKvlFNDswIFdUAolJXaAN3fDl58e+HG3JY7YalX2sjKVl5e3vWe2GKbWllst9628flV18vRAdWCsh/EDa7soMiJqzNjBn32+Ys7s+XSIj69f69ZxUCZYn+LpYXrXIMdAEQT/bt7MSkv7Y+Om9ZBwS95fae8UyKR79+0A5eAUOhBSzd5TubkpysrLUF2o5VEdx36dbKc+IAmjcxUCvHoTJkz996qP+j0/GIoaCIlq0vTnQ/sh70OK03EgxcEagQ2wiJo1axEZGRUR0QT+KVXK/Qd+qOUUnU6nVqv9/ALoQK1We/LUcXtPAjUNCGbxPnj4yMEff9z90Yera3n4Wh6VDWqZd+1sr93AAUObNIleumwhXV4PHTrKaDSu+Ww51Gl37txat37V+InDwXpBpnT56b35b548ebyktOT06d9/+/1Iq5ZtazkFioKwsIgff9qTm5dTUlIMt4BqX6ksLSuz8b6DuQkirVi55Oy5//32+9EvNqz29fOv3Ut2LY/KBrY1YMQXCpSwM2e8C79h8zdfwi5UDF9u2CqTyiZPGT32X0MupJ97c9bcZk1j4BBEiwhv8s7cGYMG9/h4+SKoyWe88U7tp8x9Z4lUIv3XuKGjxw5KaJc8ceI02B08pGd+QV6Nx4D398MPVl24cPbN2VMXL3k3JbnTtCcZ9bXclw1saPOMDQAAEABJREFUzzf976KblJEY8no4wjDEpgUZSb19k5+zYR3gvut6hKjL+AH9cQemfrDXRsMa1B/2yiICz7NjGMJuz6k925RCuMOfWSg8r6IBg+dV1B9EnfqLCNOnlAjDLFQd513jeXb1h+2yyOwOBWHqBxb7izBPCe6r4B6sAffY1kAsE1B6A8Iwh0CEBIK6zLuWuSGNBmvAJAY9CmkqtXnItgbdhvmpVbhSZozT+++KJERguMzmUdsaePrKAiPF33zA1ujds8b1c8peYwLsHa3Nd87pn+5fOFoSGCkPaSqTyR/N5nhsTna1AKrKi5Opp5Cij1V34WTyLmSKZH1jSxwrJ0NUZWcjZftej46YGpSWe1YGPj5x3BxucjpUIw5hPv3RrnmDqh7z8btXPgP93FUPUO0XEcaSh5qbV8uL8nXjF4fJZHanwzzBhxTI8OdplabcYNDVEot4wgSAp5lI/3ST7W3GeqS6Q4HVvG8xBykgSAGl8BYOey1YLKttPhJffcxamD17dp8+fXr06IF4C+/bBy6wbCnWgHuwBtyDNeAerAH3YA24B2vAPbzXQKfTiUQixGdwPuAerAH3YA24B2vAPbhO5h6cD7gHa8A9WAPu4ffTgwACgYDv8zJ5rwHfMwHCGjQEsAbcgzXgHqwB92ANuIffP8BoNDZr1gzxHH5rQJLk9evXEc/heQtTKKSdI/EarAH3YA24B2vAPVgD7sEacA/vNTAYeP/tIol4Dowf8D0r8F4DFyiO+N/ZgjXgHKwB92ANuAdrwD1YA+7BGnCPC2jA1+/04+Pj6ald9F/KTNu2bTdu3Ij4Bl/baE2bNiXNEGZgQ6FQjB8/HvEQvmowcuTIGgsDRUVFpaamIh7CVw0GDRoUHv5oiQyJRAKqIH7C4/4iKHksK9I2bty4d+/eiJ/wWINevXpFREQgs2n0wgsvIN7Cum2am1muVhpNDrRrurmq9NxVV7PM+pQhz03VFn6jcPdoFdkz82LZ05xSJwyU3q+x2MdHhtiERdt0z4ac3L80cHkjm6Mstl1zMQRBmi4uFKO/DfSJTfFB7MBWPji4OS8/S9N+gE90G7Yevd7434H8I1sLvQPEQZEKxAKs5IOtK2+pinXDZkQjF+Lr9zO6DfNtkeSNmIaVOvlBrm7Ia5HItQiPcTu5pwixAPMaHN2WLxKj2hdD5CMJz/mqy4yIBZjXwLRGK8H7YerHcVOI4VepSpg3MJivkw1aZNS6pp9moxGxkbux733uwRrUBYKVtgjWoC6wU8RiDbiHeQ1MJpHrLirFRs8OC/mAdO2lNpn/ccxrYF7313XXEGFh/URcH9QRfpRFmDrCQp1MusCMettQpgkciHGY18C8Poxr1srQ0W9kodeOBVmJutkO277f3Pu5Dlqt1hIC2z17pyxc9JZ1tP0HdnXrkXjzZlaN0+fNnz1z1hTEZ5jXgDKalv59+vgtY9vodLr0i2mWENgGy+r8hbPW0WDXz88/IqJJjdNTU3v06vU8vb1g4ZwDP+5GfIP7krtZsxYikej8+TOWENhOTu5YUlKcnZ1pCbxw4WxCu5THT+/Rvc9zffrT23/9dRWxCoEogg/tg8pFzZ4aECCubUJa2h+WkAvp59qn/O3u3fy082ciI6Mg5Nat7IcPHyQkmDQYOLjH2NETj/9+5OLF87t3HVm+/H2VSrl82edQUsHRj5ct+nztyr27j8H2Twf37tm7Izs7IzIyunu33kP+8QI9ORWKLxhiatQoaMvWTRBToajDKDEb/gvZyAdUXY3odu2Sr9+4VlJaAttlZWXwOrdo0Sqmecv09HN0hDRzLklO6oDMmu078EN0dPOPl34ql8ktF/npwAn4++asubQAvxz+6aOlC5o1jfl2856JE6Zu3/Htms+W0zHhClnZGfBv8aIVMlld5q1Q5iYo0zCvgWkMrY4vC2gAFQCdFaDMgXetbZt2bdrEwzbd5IZDUVFNPT29kPlN9PDwnD51VmJCSi0OpA4c2AVXeP21Od7ePu3ik8a9+PKuXduKigrpKxQU5C2Yt7Rjx9SGMObKSp1c154teFsVbgpaA6h7W7VqKxaLkxI7KFVKyB8gw9lzp60rg+bNYmu/oNFovHwlHa5gCYmPT4LAi5fO07vhYZFSqRQ1DBpKOzklpRNd4Fy8mNapU1fY8PX1CwkOvWi2kTQaTWJie0vkGjOuHwesW7C1vvzqM/hnHU7nA9MVJBLkGPyok+EhyTo/KNS3h48cvHfvbkbm9WlTZ9GBcXGJV69eIgkSypw2reOf/mrwjsvl8t69+oLlah0eHBSKnKFyUVWGYUEDU8VV556txATTa7533w6JRBIb25oOBA3WrvtEaDacJHV8c6OimkFRFh+XSO9CtsjPzw0IaIScgaKLWoarEBbqZMIRA87fPyAsLGL3nu2tW8VZalpIQTBJT5/6DUrzJ14BRIKLnD17GmoUvV7/0oRpJ04cgyYbVAOXLl2AVveMWS9bt8YbDizUyZSD4wcJ7ZKVytK2bRMsIVAlNG4cripT0S2DJzJq5HioVOa+N1OtUbduHbd+7TfQhhg8pNes2a+UlaneX7RC4nA1wCbMzzfdsy4/L6N81LtRyOX47/yMiQsipR4Ml0XM1wfQnnflwUxe2EWE+VNJ5JJQdeuOfEpYGT9w4eFkNmBFAyxCnWBnLNOlJ7cwDit9FS5bHyCezDd14fqA4sucXxeuDwiKjeEDPL+oAcC8BgISIVf7Fs0KXrTRDJBbee961z4UH9pomLqCNeAe5jUQiYxCiYtOOCWQgYWqjvnEcvMRGo2sfEvNLcWFalKAFArmRWBeg9RBjXRaSlXSEEesnOHswYcSN1ba/6wUGsFNJPvW3UauRX6Gps8Y54aj7cCW/6KTe++n/14S28GjXbcAxGfUau3pPfdzrqtHvx3m4SNGLMCiD6lD3+VlpZfrdeaZ2DWOUTX7Vm262oK+AdtfMlB2u2btnVKrKy+7l6P7gCVy4vnxwcERbHnzYt3HrMFgKCzQIuJRVUbPuzBa3dc0FcMI/1GWXfogQY+LmneIquSlzNOXTMNZ5niff/5ZUkJiYnIKncjWaW25Dn0hRJ9uDqWT3HwCQVCVN6HdvVFVbWHTuQaDf2N2HamhemgfCAQC/xAWf0apOkfmFecfLEK8hfdtNBdYOhZrwD1YA+7BGnAP7zXQ6XRYA47B+YB7sAbcgzXgHqgPRCIeN9AQzgcNAawB92ANuAfXB9yD8wH3YA24h99PT0/gIEl+T6XhtwYuUBkgvmvgAgURwho0BLAG3IPrA+7B+YB7eG+bxsTEIJ7Dbw2gZXDt2jXEc3jewhQKoThCPAdrwD1YA+7BGnAP1oB7sAbcw3sNDAbef5DO+49YBQIB37MC7zVwgeKI/50tWAPOwRpwD9aAe7AG3IM14B6sAfe4gAYET9fZ7d27N7TOoJFcVFQkFothA8aWw8PDd+7cifgGX/OBQqG4fbvSNUxFRQUyr0ExYcIExEP42k4eNGhQjWW1QkJC+vbti3gIXzUYMWIEJLplFzLBsGHDED/hqwZQBwwZMsSytkpwcPDAgQMRP+Fxn92oUaPorACFEpRCT1w0rcHC735TkEEmk4WFhQ0ePBjxlvqwTc8dKbyRplIW6nRa01ImRPWFPx/3vFUjpNK7kzW2HG/Z9uBlK6aNC1ouYl7vkxQgqVzgEyBq18OrcfM6rCrrGOxqsHXF7Qc5WvhlQrFA4iFW+EhFbiKBWCSo5Z4EqnLXVeWT65E/Lqso1U8yxabMrr5sXQ6Z3XcRVRex74nN5B5Mr9GpVRXlRZqKMq1RSwlEKDrOrecLQYg12NJg7/rcW3+qhRLSP8rLN9QT8Zacq/dK75bDW9Cxn0/bVB/EAqxosO6tLLhqZGKQxI2v9WQNCjIKH94s8Q0Wj5gZhpiGeQ0+nZXh4S9v3IYVV6DccuPEHUQZX1rcBDEKwxqsmZERkRSo8GLdFyJXXP/9tlROjn0nHDEHkxqseSOjSYdguXtDXJOSQTL/uGPQ6ictjkYMwVj74PM3M72C3VxeACAqubHBiLavZsyZNDMabFt5mxSSoa347Vb56WmRGlmQpc28rERMwIAGMIRy77a2eSrzBkNDxiPQ7dDXdxETMKDB1mW5Ejfef5hXV8LaBBj06NzhQuQ0DGhQdE8X0toXNVQ+Xv3Cjr1LEQvIvKTnjxUjp3FWg8NbC0gBIfdwWWO0FsLa+GtUDKx44qwGd66Vi+XP6MJGQrEQOp6O7XC2VnA2+dQqyiuMrUxgMOh//GXtn9dPFBcXRIa37Zjyz9jmnehD8z7o06fHpLLy4p+PbJCIZc2bth/49xkeHn5wqOBe1pYdC+/ez45uktCzy3jEJtAhlp+pRs7hbD4w6CnPADfEDj/sW/bbqe/+lvLPt2fuat2y+6Ytcy5ePkIfEghEx37fTBDkwrd+nv3qtuxb6QePfoFMRppuw6bXvTwDZr+6tW/vaRBHqXyAWEMsFSmLnP0AwikN1CrT7eUeUsQCOl3F2Qv7u3d+sUPyP9zknikJA+Lb9Dl07EtLBD+f0J5dxslk7vD6N49un5Nr+lD50tWjxSV3B/z9DW+vwMCAJoP7zVJrmLHibSKSC41Of4PipAY6xBp38v7U67XNolMsIVER7fLvZpSVl9C7oSEtLIdkMg9NhQo2Hjy8IxZJfbwru/s93P28PFnsPYRhVMrpFbudqg/MDrTYGgLSqE1p+umGSTXClaqHkC3MmzZ+fLm6VCyRW4eIhKxkUxpGFip2SgOvABgeIPQVeqGEedOIrmCHDnzLz6exdbi3Z2AtZ8llHhUV5dYhMB6GWEOv1YkknOYDAIZei++q/MK8ENP4+4aJRKYeQDBv6BClqhB6eSXVX/MaeHsF6XQaKLKCGpn6NXPzr5cq7yPW0JbrZHJn7RpnzxfLiNIH5YgFIK17d3vp0NEvs25d0Om1YBGt3zh9574ntHhbtkgVCsXf7/pAq9WUlN7fvO1duZzFkVSD1uAb7GxXsbP5wD9EnH+TrWUZu3UeExzU7Ohvm25knpFKFRGNW/9z4Nu1nyKTKiaMXrH/5zXvLu4OlTOYp2kXD7KywqIZg45K7OWNnMPZMZziBxWbl9xp1SsSPXvkXn2geqCa/EEUcg5nyyIvP4lMQWafy0fPHiV3lWExDIxZMWDPJPTyPrm7ti7ctV+9kpP/1+PhRqMBcqFAYPsZ5ry+Q+HGWFV/5Ph/j/y2yc5Buws5zpr2rb3mRVFeKTKiv78YipyGmfHkr+ZlEUJxZKLtiVClygfQ2rJ5SKurEItsv0o+3sGIOdRqpb0Gc1l5qZvcw+YhT48Ae6/ItWO3otrIeo1iYO4XY2P6a2ZkRHUIlilcfzwZyE7LN2i0ExcxM8mFsTH9Ds97Zf8vDz0DFBYo1UUapgRADGqQ0NOveaLi8s/ZyKVRFavyLj54ZRljE1sQ43O8MtKVB7++G9M1rMaHSq5B3rUHharcUDEAAAErSURBVLeV01YyKQBiY67jyX0P0g4Xu/vLwuMDkQtx48Rtg8748kfOtgYeh6151+vmZOi0yCvYLbQl7ycdZf2Rqy7V+gSKX3iTlfk7LH5/8NsP9y6dKIUhDqGM9PBz84vwEMt4Mw1bWVhenKMsK6rQaw0KL0HvMf7BkWx9DML6dzhX/yg6e6hEWaSnDKZPXAjS1HlDWY89PWohVX6cAdEoq+kKlPkDjhqtKPMq70S1Z3/iBz30paxGHWrsIkTvU/S9RFLCN1jcZ1QjhTe7r069fqd/I7206J5OV2YwGKx/edWnMpYUqfHhjSkpbQ4WEU83gmT6jZUfP1mpYgojjDUGgkgxcnMjA8JkIdFyVF/w1VeCK/GMTg1qUGANuAdrwD1YA+7BGnAP1oB7/g8AAP//bm+9GQAAAAZJREFUAwDOYymY0PMDvwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "try:\n",
    "    from IPython.display import Image, display\n",
    "    # Generate graph visualization\n",
    "    display(Image(app.get_graph().draw_mermaid_png()))\n",
    "except:\n",
    "    print(\"Graph visualization requires additional dependencies\")\n",
    "    print(\"Install with: pip install pygraphviz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:üîç Researcher is looking up: Latest developments in quantum computing...\n",
      "INFO:__main__:Search query: key facts and latest news about Latest developments in quantum computing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with topic: Latest developments in quantum computing\n",
      "\n",
      "============================================================\n",
      "Researcher is looking up: Latest developments in quantum computing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:ddgs.ddgs:Error in engine grokipedia: DDGSException(\"RuntimeError: RuntimeError('error sending request for url (https://wt.wikipedia.org/w/api.php?action=opensearch&profile=fuzzy&limit=1&search=key%20facts%20and%20latest%20news%20about%20Latest%20developments%20in%20quantum%20computing): client error (Connect)\\\\n\\\\nCaused by:\\\\n    0: client error (Connect)\\\\n    1: dns error: failed to lookup address information: nodename nor servname provided, or not known\\\\n    2: failed to lookup address information: nodename nor servname provided, or not known')\")\n",
      "INFO:primp:response: https://grokipedia.com/api/typeahead?query=key+facts+and+latest+news+about+Latest+developments+in+quantum+computing&limit=1 200\n",
      "INFO:primp:response: https://search.yahoo.com/search;_ylt=m8NyDD3XVum0789KTaJUSNlR;_ylu=fQTMJsl_7Vp0-YQ2WhIlHqiiO5ZxsGttG-IcWGPAlHVhIek?p=key+facts+and+latest+news+about+Latest+developments+in+quantum+computing&btf=y 200\n",
      "INFO:__main__:Search completed successfully. Results length: 1161 characters\n",
      "INFO:__main__:Research phase completed\n",
      "INFO:__main__:‚úçÔ∏è Writer is drafting the post...\n",
      "INFO:__main__:Using research data of length: 1161 characters\n",
      "INFO:__main__:LLM initialized successfully\n",
      "INFO:__main__:Invoking LLM to generate blog post...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Research complete.\n",
      "Writer is drafting the post...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Blog post generated successfully. Length: 1538 characters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Writing complete.\n",
      "\n",
      "============================================================\n",
      "RESULT\n",
      "============================================================\n",
      "Latest Developments in Quantum Computing: A Shift Toward Practicality\n",
      "\n",
      "The quantum computing landscape has seen significant advancements in recent months, with a growing focus on practical applications and near-term commercial viability. According to investment and partnership data from late 2024 through November 2025, the industry is narrowing its attention toward specific hardware architectures, cloud software platforms, security technologies, and tangible use cases. This shift reflects a recognition that quantum computing's immense potential can only be harnessed by addressing fundamental challenges and scaling up existing technology.\n",
      "\n",
      "Researchers at MIT have made significant strides in evaluating the commercial feasibility of quantum materials, identifying promising candidates for scalable success. Meanwhile, trapped ion and photonics quantum systems have attracted increasing funding, alongside rising investment in cloud-based development platforms. These developments hint at a future where quantum computing becomes a tangible reality, rather than a distant promise.\n",
      "\n",
      "As we move forward, it's clear that the quantum computing community is prioritizing practicality over pure research. With advancements in hardware and software, as well as investments in security and commercial applications, the stage is set for meaningful breakthroughs in areas like computing, communications, and national defense. As Scientific American reports, the future of quantum computing looks bright ‚Äì and we can't wait to see what's next.\n"
     ]
    }
   ],
   "source": [
    "# Example: Test with a different topic\n",
    "test_topic = \"Latest developments in quantum computing\"\n",
    "\n",
    "print(f\"Testing with topic: {test_topic}\\n\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "test_result = app.invoke({\n",
    "    \"topic\": test_topic,\n",
    "    \"research_data\": [],\n",
    "    \"blog_post\": \"\"\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"RESULT\")\n",
    "print(\"=\" * 60)\n",
    "print(test_result[\"blog_post\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Streaming Execution (Real-time Updates)\n",
    "\n",
    "For long-running workflows, you can stream the execution to see updates in real-time:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:üîç Researcher is looking up: Renewable energy innovations...\n",
      "INFO:__main__:Search query: key facts and latest news about Renewable energy innovations\n",
      "INFO:ddgs.ddgs:Error in engine grokipedia: DDGSException(\"RuntimeError: RuntimeError('error sending request for url (https://wt.wikipedia.org/w/api.php?action=opensearch&profile=fuzzy&limit=1&search=key%20facts%20and%20latest%20news%20about%20Renewable%20energy%20innovations): client error (Connect)\\\\n\\\\nCaused by:\\\\n    0: client error (Connect)\\\\n    1: dns error: failed to lookup address information: nodename nor servname provided, or not known\\\\n    2: failed to lookup address information: nodename nor servname provided, or not known')\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Streaming execution example:\n",
      "\n",
      "============================================================\n",
      "Researcher is looking up: Renewable energy innovations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:primp:response: https://grokipedia.com/api/typeahead?query=key+facts+and+latest+news+about+Renewable+energy+innovations&limit=1 200\n",
      "INFO:primp:response: https://yandex.com/search/site/?text=key+facts+and+latest+news+about+Renewable+energy+innovations&web=1&searchid=1002707 200\n",
      "INFO:__main__:Search completed successfully. Results length: 1228 characters\n",
      "INFO:__main__:Research phase completed\n",
      "INFO:__main__:‚úçÔ∏è Writer is drafting the post...\n",
      "INFO:__main__:Using research data of length: 1228 characters\n",
      "INFO:__main__:LLM initialized successfully\n",
      "INFO:__main__:Invoking LLM to generate blog post...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Research complete.\n",
      "\n",
      "üìç Node: Researcher\n",
      "   State keys updated: ['research_data']\n",
      "   Research data preview: Energy from sunlight or other renewable energy is converted to potential energy for storage in devic...\n",
      "Writer is drafting the post...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Blog post generated successfully. Length: 1107 characters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Writing complete.\n",
      "\n",
      "üìç Node: Writer\n",
      "   State keys updated: ['blog_post']\n",
      "   Blog post preview: Renewable Energy Innovations: A Game-Changer in the Making\n",
      "\n",
      "In a historic first, renewable energy ha...\n",
      "\n",
      "============================================================\n",
      "Streaming complete!\n"
     ]
    }
   ],
   "source": [
    "# Streaming execution - see state updates in real-time\n",
    "print(\"Streaming execution example:\\n\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "stream_inputs = {\n",
    "    \"topic\": \"Renewable energy innovations\",\n",
    "    \"research_data\": [],\n",
    "    \"blog_post\": \"\"\n",
    "}\n",
    "\n",
    "# Stream the execution\n",
    "# Note: The stream returns events where keys are node names and values are state updates\n",
    "for event in app.stream(stream_inputs):\n",
    "    # Each event is a dictionary with node names as keys\n",
    "    for node_name, node_output in event.items():\n",
    "        print(f\"\\nüìç Node: {node_name}\")\n",
    "        \n",
    "        # node_output is a dict containing the state updates from that node\n",
    "        if isinstance(node_output, dict):\n",
    "            print(f\"   State keys updated: {list(node_output.keys())}\")\n",
    "            \n",
    "            # Show a preview of what was updated\n",
    "            if \"research_data\" in node_output:\n",
    "                research_list = node_output[\"research_data\"]\n",
    "                if research_list and len(research_list) > 0:\n",
    "                    data_preview = str(research_list[-1])[:100] if research_list else \"None\"\n",
    "                    print(f\"   Research data preview: {data_preview}...\")\n",
    "                else:\n",
    "                    print(f\"   Research data: (empty)\")\n",
    "            \n",
    "            if \"blog_post\" in node_output:\n",
    "                post = node_output[\"blog_post\"]\n",
    "                if post:\n",
    "                    post_preview = post[:100] if len(post) > 100 else post\n",
    "                    print(f\"   Blog post preview: {post_preview}...\")\n",
    "                else:\n",
    "                    print(f\"   Blog post: (not generated yet)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Streaming complete!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspecting the Graph Structure\n",
    "\n",
    "You can inspect and visualize your graph to understand its structure:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph Nodes:\n",
      "  - __start__\n",
      "  - Researcher\n",
      "  - Writer\n",
      "  - __end__\n",
      "\n",
      "Graph Edges:\n",
      "  - Edge(source='Researcher', target='Writer', data=None, conditional=False)\n",
      "  - Edge(source='__start__', target='Researcher', data=None, conditional=False)\n",
      "  - Edge(source='Writer', target='__end__', data=None, conditional=False)\n",
      "\n",
      "Graph Structure:\n",
      "  Entry Point: Researcher\n",
      "  Number of Nodes: 4\n"
     ]
    }
   ],
   "source": [
    "# Get the compiled graph\n",
    "try:\n",
    "    graph = app.get_graph()\n",
    "    \n",
    "    # Print graph information\n",
    "    print(\"Graph Nodes:\")\n",
    "    for node in graph.nodes:\n",
    "        print(f\"  - {node}\")\n",
    "    \n",
    "    print(\"\\nGraph Edges:\")\n",
    "    # Edges might be in different formats, handle both\n",
    "    try:\n",
    "        for edge in graph.edges:\n",
    "            print(f\"  - {edge}\")\n",
    "    except:\n",
    "        # Alternative way to get edges\n",
    "        print(\"  (Edges structure may vary by LangGraph version)\")\n",
    "    \n",
    "    # Get the graph structure\n",
    "    print(\"\\nGraph Structure:\")\n",
    "    print(f\"  Entry Point: {graph.first if hasattr(graph, 'first') else 'Researcher'}\")\n",
    "    print(f\"  Number of Nodes: {len(graph.nodes)}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Note: Graph inspection encountered an issue: {e}\")\n",
    "    print(\"This is normal - the graph is still functional.\")\n",
    "    print(\"You can verify the structure by looking at the code that built it.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Troubleshooting Common Issues\n",
    "\n",
    "**Issue 1: Ollama Connection Error**\n",
    "```python\n",
    "# Check if Ollama is running\n",
    "import subprocess\n",
    "try:\n",
    "    result = subprocess.run([\"ollama\", \"list\"], capture_output=True, text=True)\n",
    "    print(\"Ollama is running!\")\n",
    "    print(result.stdout)\n",
    "except FileNotFoundError:\n",
    "    print(\"Ollama is not installed or not in PATH\")\n",
    "```\n",
    "\n",
    "**Issue 2: Model Not Found**\n",
    "```python\n",
    "# List available models\n",
    "import subprocess\n",
    "result = subprocess.run([\"ollama\", \"list\"], capture_output=True, text=True)\n",
    "print(\"Available models:\")\n",
    "print(result.stdout)\n",
    "\n",
    "# If llama3 is not listed, pull it:\n",
    "# subprocess.run([\"ollama\", \"pull\", \"llama3\"])\n",
    "```\n",
    "\n",
    "**Issue 3: Search Tool Failing**\n",
    "```python\n",
    "# Test the search tool independently\n",
    "from langchain_community.tools.ddg_search import DuckDuckGoSearchRun\n",
    "\n",
    "search = DuckDuckGoSearchRun()\n",
    "try:\n",
    "    result = search.run(\"test query\")\n",
    "    print(f\"Search works! Result: {result[:100]}...\")\n",
    "except Exception as e:\n",
    "    print(f\"Search error: {e}\")\n",
    "    print(\"This might be a network issue or DuckDuckGo API change\")\n",
    "```\n",
    "\n",
    "**Issue 4: Empty Research Data**\n",
    "```python\n",
    "# Add validation before running the full workflow\n",
    "def validate_state(state: AgentState) -> bool:\n",
    "    \"\"\"Validate that the state has required fields\"\"\"\n",
    "    if not state.get(\"topic\"):\n",
    "        print(\"Error: Topic is required\")\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "# Use before invoking\n",
    "if validate_state(inputs):\n",
    "    result = app.invoke(inputs)\n",
    "else:\n",
    "    print(\"Fix the state before proceeding\")\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the Code: Key Concepts Explained\n",
    "\n",
    "### Why TypedDict Instead of Regular Dict?\n",
    "\n",
    "TypedDict provides type hints while remaining a regular dict at runtime. This gives us:\n",
    "- **IDE Autocomplete**: Your editor knows what keys exist\n",
    "- **Type Checking**: Tools like mypy can catch errors\n",
    "- **Documentation**: Clear contract of what data is expected\n",
    "- **Runtime Safety**: LangGraph validates state structure\n",
    "\n",
    "### The Pipe Operator (|) in LangChain\n",
    "\n",
    "The `|` operator chains LangChain components:\n",
    "```python\n",
    "chain = prompt | llm\n",
    "# Equivalent to: chain = prompt.chain(llm)\n",
    "```\n",
    "\n",
    "This creates a RunnableSequence that processes data through each component in order.\n",
    "\n",
    "### State Updates in LangGraph\n",
    "\n",
    "When a node returns a dictionary, LangGraph automatically merges it with the existing state:\n",
    "```python\n",
    "# Node returns:\n",
    "return {\"research_data\": [\"new data\"]}\n",
    "\n",
    "# LangGraph merges with existing state:\n",
    "# Old state: {\"topic\": \"AI\", \"research_data\": [], \"blog_post\": \"\"}\n",
    "# New state: {\"topic\": \"AI\", \"research_data\": [\"new data\"], \"blog_post\": \"\"}\n",
    "```\n",
    "\n",
    "Only the returned keys are updated; other keys remain unchanged.\n",
    "\n",
    "### Error Handling Strategy\n",
    "\n",
    "Our error handling follows these principles:\n",
    "1. **Fail Gracefully**: Return error messages in state rather than crashing\n",
    "2. **Log Everything**: Use logging for debugging\n",
    "3. **Validate Inputs**: Check data before processing\n",
    "4. **User-Friendly Messages**: Return clear error descriptions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Reference: Key LangGraph Patterns\n",
    "\n",
    "### Pattern 1: Basic Node Function\n",
    "```python\n",
    "def my_node(state: AgentState) -> dict:\n",
    "    # Read from state\n",
    "    data = state.get(\"field_name\")\n",
    "    \n",
    "    # Do some work\n",
    "    result = process(data)\n",
    "    \n",
    "    # Return only fields to update\n",
    "    return {\"field_name\": result}\n",
    "```\n",
    "\n",
    "### Pattern 2: Error Handling in Nodes\n",
    "```python\n",
    "def safe_node(state: AgentState) -> dict:\n",
    "    try:\n",
    "        result = risky_operation(state)\n",
    "        return {\"output\": result}\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error: {e}\")\n",
    "        return {\"output\": f\"Error: {str(e)}\"}\n",
    "```\n",
    "\n",
    "### Pattern 3: Conditional Routing\n",
    "```python\n",
    "def router(state: AgentState) -> str:\n",
    "    if condition(state):\n",
    "        return \"NodeA\"\n",
    "    else:\n",
    "        return \"NodeB\"\n",
    "\n",
    "workflow.add_conditional_edges(\"DecisionNode\", router)\n",
    "```\n",
    "\n",
    "### Pattern 4: State Validation\n",
    "```python\n",
    "def validate_state(state: AgentState) -> bool:\n",
    "    required_fields = [\"topic\", \"research_data\"]\n",
    "    return all(field in state for field in required_fields)\n",
    "```\n",
    "\n",
    "### Common LangGraph Methods\n",
    "- `StateGraph(StateClass)` - Create a new graph\n",
    "- `add_node(name, function)` - Add a node\n",
    "- `set_entry_point(name)` - Set starting node\n",
    "- `add_edge(from_node, to_node)` - Add linear edge\n",
    "- `add_conditional_edges(node, condition_func)` - Add conditional routing\n",
    "- `compile()` - Build executable graph\n",
    "- `invoke(state)` - Run graph synchronously\n",
    "- `stream(state)` - Run graph with streaming updates\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI Agents",
   "language": "python",
   "name": "ai-agents"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
